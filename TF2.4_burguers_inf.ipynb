{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2_burguers_inf.ipynb",
      "provenance": [],
      "mount_file_id": "1p2QAEGT6uVtKq9w6GhZ38yd0VgsREGyb",
      "authorship_tag": "ABX9TyP+vEXkoqoch0jvadC6WbOq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pauloacs/DeepCFD/blob/main/TF2.4_burguers_inf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-9dtN1K5yc1",
        "outputId": "9f5c7075-4ef7-435e-fe39-90d8ca7c6e09"
      },
      "source": [
        "pip install --upgrade pyDOE"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyDOE\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/ac/91fe4c039e2744466621343d3b8af4a485193ed0aab53af5b1db03be0989/pyDOE-0.3.8.zip\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from pyDOE) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from pyDOE) (1.4.1)\n",
            "Building wheels for collected packages: pyDOE\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyDOE: filename=pyDOE-0.3.8-cp36-none-any.whl size=18178 sha256=ea2a10c2a19347b468f6175c310de7719405396560887fcaf2267c28e0df52a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/c8/58/a6493bd415e8ba5735082b5e0c096d7c1f2933077a8ce34544\n",
            "Successfully built pyDOE\n",
            "Installing collected packages: pyDOE\n",
            "Successfully installed pyDOE-0.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m11J46MtBwJO",
        "outputId": "2b7be56c-c3d8-4e5a-86eb-e9f349c98e16"
      },
      "source": [
        "! sudo apt-get install texlive-latex-recommended \n",
        "! sudo apt-get install dvipng texlive-latex-extra texlive-fonts-recommended  \n",
        "! wget http://mirrors.ctan.org/macros/latex/contrib/type1cm.zip \n",
        "! unzip type1cm.zip -d /tmp/type1cm \n",
        "! cd /tmp/type1cm/type1cm/ && sudo latex type1cm.ins\n",
        "! sudo mkdir /usr/share/texmf/tex/latex/type1cm \n",
        "! sudo cp /tmp/type1cm/type1cm/type1cm.sty /usr/share/texmf/tex/latex/type1cm \n",
        "! sudo texhash \n",
        "!apt install cm-super"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-lmodern fonts-noto-mono libcupsfilters1\n",
            "  libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0 libkpathsea6\n",
            "  libpotrace0 libptexenc1 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13\n",
            "  lmodern poppler-data t1utils tex-common texlive-base texlive-binaries\n",
            "  texlive-latex-base\n",
            "Suggested packages:\n",
            "  fonts-noto poppler-utils ghostscript fonts-japanese-mincho\n",
            "  | fonts-ipafont-mincho fonts-japanese-gothic | fonts-ipafont-gothic\n",
            "  fonts-arphic-ukai fonts-arphic-uming fonts-nanum debhelper gv\n",
            "  | postscript-viewer perl-tk xpdf-reader | pdf-viewer texlive-latex-base-doc\n",
            "  texlive-latex-recommended-doc texlive-pstricks\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-lmodern fonts-noto-mono libcupsfilters1\n",
            "  libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0 libkpathsea6\n",
            "  libpotrace0 libptexenc1 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13\n",
            "  lmodern poppler-data t1utils tex-common texlive-base texlive-binaries\n",
            "  texlive-latex-base texlive-latex-recommended\n",
            "0 upgraded, 24 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 68.4 MB of archives.\n",
            "After this operation, 223 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.14 [5,092 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [2,265 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 lmodern all 2.004.5-3 [9,631 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-recommended all 2017.20180305-1 [14.9 MB]\n",
            "Fetched 68.4 MB in 8s (8,112 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 24.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 146442 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../01-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../02-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../03-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../04-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../05-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../06-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../07-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../08-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.14_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../10-libgs9_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../11-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../12-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../13-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../14-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../15-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../16-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../17-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../18-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../19-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../20-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../21-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../22-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../23-texlive-latex-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2017.20180305-1) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up lmodern (2.004.5-3) ...\n",
            "Setting up texlive-latex-recommended (2017.20180305-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-lato fonts-texgyre ghostscript gsfonts javascript-common libjs-jquery\n",
            "  libruby2.5 preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration tex-gyre texlive-pictures texlive-plain-generic tipa\n",
            "Suggested packages:\n",
            "  ghostscript-x apache2 | lighttpd | httpd ri ruby-dev bundler\n",
            "  texlive-fonts-recommended-doc python-pygments icc-profiles\n",
            "  libfile-which-perl libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  dot2tex prerex ruby-tcltk | libtcltk-ruby texlive-pictures-doc vprerex\n",
            "The following NEW packages will be installed:\n",
            "  dvipng fonts-lato fonts-texgyre ghostscript gsfonts javascript-common\n",
            "  libjs-jquery libruby2.5 preview-latex-style rake ruby ruby-did-you-mean\n",
            "  ruby-minitest ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration tex-gyre texlive-fonts-recommended texlive-latex-extra\n",
            "  texlive-pictures texlive-plain-generic tipa\n",
            "0 upgraded, 24 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 69.8 MB of archives.\n",
            "After this operation, 221 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lato all 2.0-2 [2,698 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [51.3 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 dvipng amd64 1.15-1 [78.2 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-texgyre all 20160520-1 [8,761 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 rubygems-integration all 1.11 [4,994 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ruby2.5 amd64 2.5.1-1ubuntu1.7 [48.6 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby amd64 1:2.5.1 [5,712 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 rake all 12.3.1-1ubuntu0.1 [44.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-did-you-mean all 1.2.0-2 [9,700 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-minitest all 5.10.3-1 [38.6 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-power-assert all 0.3.0-1 [7,952 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-test-unit all 3.2.5-1 [61.1 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libruby2.5 amd64 2.5.1-1ubuntu1.7 [3,068 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 preview-latex-style all 11.91-1ubuntu1 [185 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tex-gyre all 20160520-1 [4,998 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-recommended all 2017.20180305-1 [5,262 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-pictures all 2017.20180305-1 [4,026 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-latex-extra all 2017.20180305-2 [10.6 MB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-plain-generic all 2017.20180305-2 [23.6 MB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tipa all 2:1.3-20 [2,978 kB]\n",
            "Fetched 69.8 MB in 9s (8,045 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 24.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-lato.\n",
            "(Reading database ... 153776 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-lato_2.0-2_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../01-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n",
            "Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package dvipng.\n",
            "Preparing to unpack .../02-dvipng_1.15-1_amd64.deb ...\n",
            "Unpacking dvipng (1.15-1) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../03-fonts-texgyre_20160520-1_all.deb ...\n",
            "Unpacking fonts-texgyre (20160520-1) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../04-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../05-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../06-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../07-rubygems-integration_1.11_all.deb ...\n",
            "Unpacking rubygems-integration (1.11) ...\n",
            "Selecting previously unselected package ruby2.5.\n",
            "Preparing to unpack .../08-ruby2.5_2.5.1-1ubuntu1.7_amd64.deb ...\n",
            "Unpacking ruby2.5 (2.5.1-1ubuntu1.7) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../09-ruby_1%3a2.5.1_amd64.deb ...\n",
            "Unpacking ruby (1:2.5.1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../10-rake_12.3.1-1ubuntu0.1_all.deb ...\n",
            "Unpacking rake (12.3.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-did-you-mean.\n",
            "Preparing to unpack .../11-ruby-did-you-mean_1.2.0-2_all.deb ...\n",
            "Unpacking ruby-did-you-mean (1.2.0-2) ...\n",
            "Selecting previously unselected package ruby-minitest.\n",
            "Preparing to unpack .../12-ruby-minitest_5.10.3-1_all.deb ...\n",
            "Unpacking ruby-minitest (5.10.3-1) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../13-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-power-assert.\n",
            "Preparing to unpack .../14-ruby-power-assert_0.3.0-1_all.deb ...\n",
            "Unpacking ruby-power-assert (0.3.0-1) ...\n",
            "Selecting previously unselected package ruby-test-unit.\n",
            "Preparing to unpack .../15-ruby-test-unit_3.2.5-1_all.deb ...\n",
            "Unpacking ruby-test-unit (3.2.5-1) ...\n",
            "Selecting previously unselected package libruby2.5:amd64.\n",
            "Preparing to unpack .../16-libruby2.5_2.5.1-1ubuntu1.7_amd64.deb ...\n",
            "Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.7) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../17-preview-latex-style_11.91-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (11.91-1ubuntu1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../18-tex-gyre_20160520-1_all.deb ...\n",
            "Unpacking tex-gyre (20160520-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../19-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../20-texlive-pictures_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-pictures (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../21-texlive-latex-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-latex-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../22-texlive-plain-generic_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-plain-generic (2017.20180305-2) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../23-tipa_2%3a1.3-20_all.deb ...\n",
            "Unpacking tipa (2:1.3-20) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up texlive-pictures (2017.20180305-1) ...\n",
            "Setting up tex-gyre (20160520-1) ...\n",
            "Setting up tipa (2:1.3-20) ...\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-DEBIAN'... done.\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST'... done.\n",
            "update-fmtutil has updated the following file(s):\n",
            "\t/var/lib/texmf/fmtutil.cnf-DEBIAN\n",
            "\t/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST\n",
            "If you want to activate the changes in the above file(s),\n",
            "you should run fmtutil-sys or fmtutil.\n",
            "Setting up preview-latex-style (11.91-1ubuntu1) ...\n",
            "Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up fonts-texgyre (20160520-1) ...\n",
            "Setting up fonts-lato (2.0-2) ...\n",
            "Setting up ruby-did-you-mean (1.2.0-2) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up rubygems-integration (1.11) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-plain-generic (2017.20180305-2) ...\n",
            "Setting up ruby-minitest (5.10.3-1) ...\n",
            "Setting up ruby-power-assert (0.3.0-1) ...\n",
            "Setting up texlive-latex-extra (2017.20180305-2) ...\n",
            "Setting up dvipng (1.15-1) ...\n",
            "Setting up rake (12.3.1-1ubuntu0.1) ...\n",
            "Setting up ruby2.5 (2.5.1-1ubuntu1.7) ...\n",
            "Setting up ruby (1:2.5.1) ...\n",
            "Setting up ruby-test-unit (3.2.5-1) ...\n",
            "Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.7) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running mktexlsr. This may take some time... done.\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "--2021-02-21 14:39:39--  http://mirrors.ctan.org/macros/latex/contrib/type1cm.zip\n",
            "Resolving mirrors.ctan.org (mirrors.ctan.org)... 5.35.249.60\n",
            "Connecting to mirrors.ctan.org (mirrors.ctan.org)|5.35.249.60|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://ctan.mirrors.hoobly.com/macros/latex/contrib/type1cm.zip [following]\n",
            "--2021-02-21 14:39:40--  http://ctan.mirrors.hoobly.com/macros/latex/contrib/type1cm.zip\n",
            "Resolving ctan.mirrors.hoobly.com (ctan.mirrors.hoobly.com)... 69.64.41.166\n",
            "Connecting to ctan.mirrors.hoobly.com (ctan.mirrors.hoobly.com)|69.64.41.166|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 328566 (321K) [application/zip]\n",
            "Saving to: ‘type1cm.zip’\n",
            "\n",
            "type1cm.zip         100%[===================>] 320.87K   467KB/s    in 0.7s    \n",
            "\n",
            "2021-02-21 14:39:41 (467 KB/s) - ‘type1cm.zip’ saved [328566/328566]\n",
            "\n",
            "Archive:  type1cm.zip\n",
            "   creating: /tmp/type1cm/type1cm/\n",
            "  inflating: /tmp/type1cm/type1cm/type1cm.fdd  \n",
            "  inflating: /tmp/type1cm/type1cm/type1cm.ins  \n",
            "  inflating: /tmp/type1cm/type1cm/type1cm.txt  \n",
            "  inflating: /tmp/type1cm/type1cm/type1cm-doc.pdf  \n",
            "  inflating: /tmp/type1cm/type1cm/type1cm-doc.tex  \n",
            "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017/Debian) (preloaded format=latex)\n",
            " restricted \\write18 enabled.\n",
            "entering extended mode\n",
            "(./type1cm.ins\n",
            "LaTeX2e <2017-04-15>\n",
            "Babel <3.18> and hyphenation patterns for 3 language(s) loaded.\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/base/docstrip.tex\n",
            "Utility: `docstrip' 2.5e <2014/09/29>\n",
            "English documentation    <2017/03/13>\n",
            "\n",
            "**********************************************************\n",
            "* This program converts documented macro-files into fast *\n",
            "* loadable files by stripping off (nearly) all comments! *\n",
            "**********************************************************\n",
            "\n",
            "********************************************************\n",
            "* No Configuration file found, using default settings. *\n",
            "********************************************************\n",
            "\n",
            "(./type1cm.ins\n",
            "\n",
            "Generating file(s) ./type1cm.sty \n",
            "\n",
            "Processing file type1cm.fdd (package,ams) -> type1cm.sty\n",
            "Lines  processed: 410\n",
            "Comments removed: 25\n",
            "Comments  passed: 7\n",
            "Codelines passed: 263\n",
            "\n",
            ") ) )\n",
            "No pages of output.\n",
            "Transcript written on type1cm.log.\n",
            "texhash: Updating /usr/local/share/texmf/ls-R... \n",
            "texhash: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "texhash: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "texhash: Updating /var/lib/texmf/ls-R... \n",
            "texhash: Done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cm-super-minimal pfb2t1c2pfb\n",
            "The following NEW packages will be installed:\n",
            "  cm-super cm-super-minimal pfb2t1c2pfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 24.5 MB of archives.\n",
            "After this operation, 59.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super-minimal all 0.3.4-11 [5,810 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 pfb2t1c2pfb amd64 0.3-11 [9,342 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super all 0.3.4-11 [18.7 MB]\n",
            "Fetched 24.5 MB in 4s (5,467 kB/s)\n",
            "Selecting previously unselected package cm-super-minimal.\n",
            "(Reading database ... 172320 files and directories currently installed.)\n",
            "Preparing to unpack .../cm-super-minimal_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super-minimal (0.3.4-11) ...\n",
            "Selecting previously unselected package pfb2t1c2pfb.\n",
            "Preparing to unpack .../pfb2t1c2pfb_0.3-11_amd64.deb ...\n",
            "Unpacking pfb2t1c2pfb (0.3-11) ...\n",
            "Selecting previously unselected package cm-super.\n",
            "Preparing to unpack .../cm-super_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super (0.3.4-11) ...\n",
            "Setting up pfb2t1c2pfb (0.3-11) ...\n",
            "Setting up cm-super-minimal (0.3.4-11) ...\n",
            "Setting up cm-super (0.3.4-11) ...\n",
            "Creating fonts. This may take some time... done.\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "Running mktexlsr. This may take some time... done.\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwzqFDFK7fq1",
        "outputId": "d215a480-cf84-4a1d-aed1-7c14937bddbe"
      },
      "source": [
        "import sys\n",
        "#eqnPath = \"1d-burgers\"\n",
        "#sys.path.append(eqnPath)\n",
        "#sys.path.append(\"utils\")\n",
        "print(sys.argv) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py', '-f', '/root/.local/share/jupyter/runtime/kernel-154e6348-878c-41a7-8f1e-74badd756054.json']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsfAE7ns_ORH"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "\n",
        "def saveResultDir(save_path, save_hp):\n",
        "    now = datetime.now()\n",
        "    scriptName =  os.path.splitext(os.path.basename(sys.argv[0]))[0]\n",
        "    resDir = os.path.join(save_path, \"results\", f\"{now.strftime('%Y%m%d-%H%M%S')}-{scriptName}\")\n",
        "    os.mkdir(resDir)\n",
        "    print(\"Saving results to directory \", resDir)\n",
        "    savefig(os.path.join(resDir, \"graph\"))\n",
        "    with open(os.path.join(resDir, \"hp.json\"), \"w\") as f:\n",
        "        json.dump(save_hp, f)\n",
        "\n",
        "\n",
        "# MIT License\n",
        "# \n",
        "# Copyright (c) 2018 maziarraissi\n",
        "# \n",
        "# https://github.com/maziarraissi/PINNs\n",
        "\n",
        "def figsize(scale, nplots = 1):\n",
        "    fig_width_pt = 390.0                          # Get this from LaTeX using \\the\\textwidth\n",
        "    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n",
        "    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n",
        "    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n",
        "    fig_height = nplots*fig_width*golden_mean              # height in inches\n",
        "    fig_size = [fig_width,fig_height]\n",
        "    return fig_size\n",
        "\n",
        "pgf_with_latex = {                      # setup matplotlib to use latex for output\n",
        "    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n",
        "    \"text.usetex\": True,                # use LaTeX to write all text\n",
        "    \"font.family\": \"serif\",\n",
        "    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n",
        "    \"font.sans-serif\": [],\n",
        "    \"font.monospace\": [],\n",
        "    \"axes.labelsize\": 10,               # LaTeX default is 10pt font.\n",
        "    \"font.size\": 10,\n",
        "    \"legend.fontsize\": 8,               # Make the legend/label fonts a little smaller\n",
        "    \"xtick.labelsize\": 8,\n",
        "    \"ytick.labelsize\": 8,\n",
        "    \"figure.figsize\": figsize(1.0),     # default fig size of 0.9 textwidth\n",
        "    \"pgf.preamble\": [\n",
        "        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n",
        "        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n",
        "        ]\n",
        "    }\n",
        "mpl.rcParams.update(pgf_with_latex)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# I make my own newfig and savefig functions\n",
        "def newfig(width, nplots = 1):\n",
        "    fig = plt.figure(figsize=figsize(width, nplots))\n",
        "    ax = fig.add_subplot(111)\n",
        "    return fig, ax\n",
        "\n",
        "def savefig(filename, crop = True):\n",
        "    if crop == True:\n",
        "#        plt.savefig('{}.pgf'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "        plt.savefig('{}.pdf'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "        # plt.savefig('{}.eps'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "        plt.savefig('{}.png'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "    else:\n",
        "#        plt.savefig('{}.pgf'.format(filename))\n",
        "        plt.savefig('{}.pdf'.format(filename))\n",
        "        # plt.savefig('{}.eps'.format(filename))\n",
        "        plt.savefig('{}.png'.format(filename))\n",
        "\n",
        "## Simple plot\n",
        "#fig, ax  = newfig(1.0)\n",
        "#\n",
        "#def ema(y, a):\n",
        "#    s = []\n",
        "#    s.append(y[0])\n",
        "#    for t in range(1, len(y)):\n",
        "#        s.append(a * y[t] + (1-a) * s[t-1])\n",
        "#    return np.array(s)\n",
        "#    \n",
        "#y = [0]*200\n",
        "#y.extend([20]*(1000-len(y)))\n",
        "#s = ema(y, 0.01)\n",
        "#\n",
        "#ax.plot(s)\n",
        "#ax.set_xlabel('X Label')\n",
        "#ax.set_ylabel('EMA')\n",
        "#\n",
        "#savefig('ema')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njniDEGr77xp"
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "class Logger(object):\n",
        "    def __init__(self, hp):\n",
        "        print(\"Hyperparameters:\")\n",
        "        print(json.dumps(hp, indent=2))\n",
        "        print()\n",
        "\n",
        "        print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "        print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
        "        print(\"GPU-accerelated: {}\".format(tf.test.is_gpu_available()))\n",
        "\n",
        "        self.start_time = time.time()\n",
        "        self.prev_time = self.start_time\n",
        "        self.frequency = hp[\"log_frequency\"]\n",
        "\n",
        "    def get_epoch_duration(self):\n",
        "        now = time.time()\n",
        "        edur = datetime.fromtimestamp(now - self.prev_time) \\\n",
        "            .strftime(\"%S.%f\")[:-5]\n",
        "        self.prev_time = now\n",
        "        return edur\n",
        "\n",
        "    def get_elapsed(self):\n",
        "        return datetime.fromtimestamp(time.time() - self.start_time) \\\n",
        "                .strftime(\"%M:%S\")\n",
        "\n",
        "    def get_error_u(self):\n",
        "        return self.error_fn()\n",
        "\n",
        "    def set_error_fn(self, error_fn):\n",
        "        self.error_fn = error_fn\n",
        "\n",
        "    def log_train_start(self, model, model_description=False):\n",
        "        print(\"\\nTraining started\")\n",
        "        print(\"================\")\n",
        "        self.model = model\n",
        "        if model_description:\n",
        "            print(model.summary())\n",
        "\n",
        "    def log_train_epoch(self, epoch, loss, custom=\"\", is_iter=False):\n",
        "        if epoch % self.frequency == 0:\n",
        "            name = 'nt_epoch' if is_iter else 'tf_epoch'\n",
        "            print(f\"{name} = {epoch:6d}  \" +\n",
        "                  f\"elapsed = {self.get_elapsed()} \" +\n",
        "                  f\"(+{self.get_epoch_duration()})  \" +\n",
        "                  f\"loss = {loss:.4e}  \" + custom)\n",
        "\n",
        "    def log_train_opt(self, name):\n",
        "        print(f\"-- Starting {name} optimization --\")\n",
        "\n",
        "    def log_train_end(self, epoch, custom=\"\"):\n",
        "        print(\"==================\")\n",
        "        print(f\"Training finished (epoch {epoch}): \" +\n",
        "              f\"duration = {self.get_elapsed()}  \" +\n",
        "              f\"error = {self.get_error_u():.4e}  \" + custom)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI14rDnv78rH"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork(object):\n",
        "    def __init__(self, hp, logger, ub, lb):\n",
        "\n",
        "        layers = hp[\"layers\"]\n",
        "\n",
        "        # Setting up the optimizers with the hyper-parameters\n",
        "        self.nt_config = Struct()\n",
        "        self.nt_config.learningRate = hp[\"nt_lr\"]\n",
        "        self.nt_config.maxIter = hp[\"nt_epochs\"]\n",
        "        self.nt_config.nCorrection = hp[\"nt_ncorr\"]\n",
        "        self.nt_config.tolFun = 1.0 * np.finfo(float).eps\n",
        "        self.tf_epochs = hp[\"tf_epochs\"]\n",
        "        self.tf_optimizer = tf.keras.optimizers.Adam(\n",
        "            learning_rate=hp[\"tf_lr\"],\n",
        "            beta_1=hp[\"tf_b1\"],\n",
        "            epsilon=hp[\"tf_eps\"])\n",
        "\n",
        "        self.dtype = \"float64\"\n",
        "        # Descriptive Keras model\n",
        "        tf.keras.backend.set_floatx(self.dtype)\n",
        "        self.model = tf.keras.Sequential()\n",
        "        self.model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
        "        self.model.add(tf.keras.layers.Lambda(\n",
        "            lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
        "        for width in layers[1:-1]:\n",
        "            self.model.add(tf.keras.layers.Dense(\n",
        "                width, activation=tf.nn.tanh,\n",
        "                kernel_initializer=\"glorot_normal\"))\n",
        "        self.model.add(tf.keras.layers.Dense(\n",
        "                layers[-1], activation=None,\n",
        "                kernel_initializer=\"glorot_normal\"))\n",
        "\n",
        "        # Computing the sizes of weights/biases for future decomposition\n",
        "        self.sizes_w = []\n",
        "        self.sizes_b = []\n",
        "        for i, width in enumerate(layers):\n",
        "            if i != 1:\n",
        "                self.sizes_w.append(int(width * layers[1]))\n",
        "                self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
        "\n",
        "        self.logger = logger\n",
        "\n",
        "    # Defining custom loss\n",
        "    # @tf.function\n",
        "    def loss(self, u, u_pred):\n",
        "        return tf.reduce_mean(tf.square(u - u_pred))\n",
        "\n",
        "    # @tf.function\n",
        "    def grad(self, X, u):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss_value = self.loss(u, self.model(X))\n",
        "        grads = tape.gradient(loss_value, self.wrap_training_variables())\n",
        "        return loss_value, grads\n",
        "\n",
        "    def wrap_training_variables(self):\n",
        "        var = self.model.trainable_variables\n",
        "        return var\n",
        "\n",
        "    def get_params(self, numpy=False):\n",
        "        return []\n",
        "\n",
        "    def get_weights(self, convert_to_tensor=True):\n",
        "        w = []\n",
        "        for layer in self.model.layers[1:]:\n",
        "            weights_biases = layer.get_weights()\n",
        "            weights = weights_biases[0].flatten()\n",
        "            biases = weights_biases[1]\n",
        "            w.extend(weights)\n",
        "            w.extend(biases)\n",
        "        if convert_to_tensor:\n",
        "            w = self.tensor(w)\n",
        "        return w\n",
        "\n",
        "    def set_weights(self, w):\n",
        "        for i, layer in enumerate(self.model.layers[1:]):\n",
        "            start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
        "            end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
        "            weights = w[start_weights:end_weights]\n",
        "            w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
        "            weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
        "            biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
        "            weights_biases = [weights, biases]\n",
        "            layer.set_weights(weights_biases)\n",
        "\n",
        "    def get_loss_and_flat_grad(self, X, u):\n",
        "        def loss_and_flat_grad(w):\n",
        "            with tf.GradientTape() as tape:\n",
        "                self.set_weights(w)\n",
        "                loss_value = self.loss(u, self.model(X))\n",
        "            grad = tape.gradient(loss_value, self.wrap_training_variables())\n",
        "            grad_flat = []\n",
        "            for g in grad:\n",
        "                grad_flat.append(tf.reshape(g, [-1]))\n",
        "            grad_flat = tf.concat(grad_flat, 0)\n",
        "            return loss_value, grad_flat\n",
        "\n",
        "        return loss_and_flat_grad\n",
        "\n",
        "    def tf_optimization(self, X_u, u):\n",
        "        self.logger.log_train_opt(\"Adam\")\n",
        "        for epoch in range(self.tf_epochs):\n",
        "            loss_value = self.tf_optimization_step(X_u, u)\n",
        "            self.logger.log_train_epoch(epoch, loss_value)\n",
        "\n",
        "    # @tf.function\n",
        "    def tf_optimization_step(self, X_u, u):\n",
        "        loss_value, grads = self.grad(X_u, u)\n",
        "        self.tf_optimizer.apply_gradients(\n",
        "                zip(grads, self.wrap_training_variables()))\n",
        "        return loss_value\n",
        "\n",
        "    def nt_optimization(self, X_u, u):\n",
        "        self.logger.log_train_opt(\"LBFGS\")\n",
        "        loss_and_flat_grad = self.get_loss_and_flat_grad(X_u, u)\n",
        "        # tfp.optimizer.lbfgs_minimize(\n",
        "        #   loss_and_flat_grad,\n",
        "        #   initial_position=self.get_weights(),\n",
        "        #   num_correction_pairs=nt_config.nCorrection,\n",
        "        #   max_iterations=nt_config.maxIter,\n",
        "        #   f_relative_tolerance=nt_config.tolFun,\n",
        "        #   tolerance=nt_config.tolFun,\n",
        "        #   parallel_iterations=6)\n",
        "        self.nt_optimization_steps(loss_and_flat_grad)\n",
        "\n",
        "    def nt_optimization_steps(self, loss_and_flat_grad):\n",
        "        lbfgs(loss_and_flat_grad,\n",
        "              self.get_weights(),\n",
        "              self.nt_config, Struct(), True,\n",
        "              lambda epoch, loss, is_iter:\n",
        "              self.logger.log_train_epoch(epoch, loss, \"\", is_iter))\n",
        "\n",
        "    def fit(self, X_u, u):\n",
        "        self.logger.log_train_start(self)\n",
        "\n",
        "        # Creating the tensors\n",
        "        X_u = self.tensor(X_u)\n",
        "        u = self.tensor(u)\n",
        "\n",
        "        # Optimizing\n",
        "        self.tf_optimization(X_u, u)\n",
        "        self.nt_optimization(X_u, u)\n",
        "\n",
        "        self.logger.log_train_end(self.tf_epochs + self.nt_config.maxIter)\n",
        "\n",
        "    def predict(self, X_star):\n",
        "        u_pred = self.model(X_star)\n",
        "        return u_pred.numpy()\n",
        "\n",
        "    def summary(self):\n",
        "        return self.model.summary()\n",
        "\n",
        "    def tensor(self, X):\n",
        "        return tf.convert_to_tensor(X, dtype=self.dtype)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PRe016z_GqJ"
      },
      "source": [
        "#%% Adapted from https://github.com/yaroslavvb/stuff/blob/master/eager_lbfgs/eager_lbfgs.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Time tracking functions\n",
        "global_time_list = []\n",
        "global_last_time = 0\n",
        "def reset_time():\n",
        "  global global_time_list, global_last_time\n",
        "  global_time_list = []\n",
        "  global_last_time = time.perf_counter()\n",
        "  \n",
        "def record_time():\n",
        "  global global_last_time, global_time_list\n",
        "  new_time = time.perf_counter()\n",
        "  global_time_list.append(new_time - global_last_time)\n",
        "  global_last_time = time.perf_counter()\n",
        "  #print(\"step: %.2f\"%(global_time_list[-1]*1000))\n",
        "\n",
        "def last_time():\n",
        "  \"\"\"Returns last interval records in millis.\"\"\"\n",
        "  global global_last_time, global_time_list\n",
        "  if global_time_list:\n",
        "    return 1000 * global_time_list[-1]\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def dot(a, b):\n",
        "  \"\"\"Dot product function since TensorFlow doesn't have one.\"\"\"\n",
        "  return tf.reduce_sum(a*b)\n",
        "\n",
        "def verbose_func(s):\n",
        "  print(s)\n",
        "\n",
        "final_loss = None\n",
        "times = []\n",
        "def lbfgs(opfunc, x, config, state, do_verbose, log_fn):\n",
        "  \"\"\"port of lbfgs.lua, using TensorFlow eager mode.\n",
        "  \"\"\"\n",
        "\n",
        "  if config.maxIter == 0:\n",
        "    return\n",
        "\n",
        "  global final_loss, times\n",
        "  \n",
        "  maxIter = config.maxIter\n",
        "  maxEval = config.maxEval or maxIter*1.25\n",
        "  tolFun = config.tolFun or 1e-5\n",
        "  tolX = config.tolX or 1e-19\n",
        "  nCorrection = config.nCorrection or 100\n",
        "  lineSearch = config.lineSearch\n",
        "  lineSearchOpts = config.lineSearchOptions\n",
        "  learningRate = config.learningRate or 1\n",
        "  isverbose = config.verbose or False\n",
        "\n",
        "  # verbose function\n",
        "  if isverbose:\n",
        "    verbose = verbose_func\n",
        "  else:\n",
        "    verbose = lambda x: None\n",
        "\n",
        "    # evaluate initial f(x) and df/dx\n",
        "  f, g = opfunc(x)\n",
        "\n",
        "  f_hist = [f]\n",
        "  currentFuncEval = 1\n",
        "  state.funcEval = state.funcEval + 1\n",
        "  p = g.shape[0]\n",
        "\n",
        "  # check optimality of initial point\n",
        "  tmp1 = tf.abs(g)\n",
        "  if tf.reduce_sum(tmp1) <= tolFun:\n",
        "    verbose(\"optimality condition below tolFun\")\n",
        "    return x, f_hist\n",
        "\n",
        "  # optimize for a max of maxIter iterations\n",
        "  nIter = 0\n",
        "  times = []\n",
        "  while nIter < maxIter:\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # keep track of nb of iterations\n",
        "    nIter = nIter + 1\n",
        "    state.nIter = state.nIter + 1\n",
        "\n",
        "    ############################################################\n",
        "    ## compute gradient descent direction\n",
        "    ############################################################\n",
        "    if state.nIter == 1:\n",
        "      d = -g\n",
        "      old_dirs = []\n",
        "      old_stps = []\n",
        "      Hdiag = 1\n",
        "    else:\n",
        "      # do lbfgs update (update memory)\n",
        "      y = g - g_old\n",
        "      s = d*t\n",
        "      ys = dot(y, s)\n",
        "      \n",
        "      if ys > 1e-10:\n",
        "        # updating memory\n",
        "        if len(old_dirs) == nCorrection:\n",
        "          # shift history by one (limited-memory)\n",
        "          del old_dirs[0]\n",
        "          del old_stps[0]\n",
        "\n",
        "        # store new direction/step\n",
        "        old_dirs.append(s)\n",
        "        old_stps.append(y)\n",
        "\n",
        "        # update scale of initial Hessian approximation\n",
        "        Hdiag = ys/dot(y, y)\n",
        "\n",
        "      # compute the approximate (L-BFGS) inverse Hessian \n",
        "      # multiplied by the gradient\n",
        "      k = len(old_dirs)\n",
        "\n",
        "      # need to be accessed element-by-element, so don't re-type tensor:\n",
        "      ro = [0]*nCorrection\n",
        "      for i in range(k):\n",
        "        ro[i] = 1/dot(old_stps[i], old_dirs[i])\n",
        "        \n",
        "\n",
        "      # iteration in L-BFGS loop collapsed to use just one buffer\n",
        "      # need to be accessed element-by-element, so don't re-type tensor:\n",
        "      al = [0]*nCorrection\n",
        "\n",
        "      q = -g\n",
        "      for i in range(k-1, -1, -1):\n",
        "        al[i] = dot(old_dirs[i], q) * ro[i]\n",
        "        q = q - al[i]*old_stps[i]\n",
        "\n",
        "      # multiply by initial Hessian\n",
        "      r = q*Hdiag\n",
        "      for i in range(k):\n",
        "        be_i = dot(old_stps[i], r) * ro[i]\n",
        "        r += (al[i]-be_i)*old_dirs[i]\n",
        "        \n",
        "      d = r\n",
        "      # final direction is in r/d (same object)\n",
        "\n",
        "    g_old = g\n",
        "    f_old = f\n",
        "    \n",
        "    ############################################################\n",
        "    ## compute step length\n",
        "    ############################################################\n",
        "    # directional derivative\n",
        "    gtd = dot(g, d)\n",
        "\n",
        "    # check that progress can be made along that direction\n",
        "    if gtd > -tolX:\n",
        "      verbose(\"Can not make progress along direction.\")\n",
        "      break\n",
        "\n",
        "    # reset initial guess for step size\n",
        "    if state.nIter == 1:\n",
        "      tmp1 = tf.abs(g)\n",
        "      t = min(1, 1/tf.reduce_sum(tmp1))\n",
        "    else:\n",
        "      t = learningRate\n",
        "\n",
        "\n",
        "    # optional line search: user function\n",
        "    lsFuncEval = 0\n",
        "    if lineSearch and isinstance(lineSearch) == types.FunctionType:\n",
        "      # perform line search, using user function\n",
        "      f,g,x,t,lsFuncEval = lineSearch(opfunc,x,t,d,f,g,gtd,lineSearchOpts)\n",
        "      f_hist.append(f)\n",
        "    else:\n",
        "      # no line search, simply move with fixed-step\n",
        "      x += t*d\n",
        "      \n",
        "      if nIter != maxIter:\n",
        "        # re-evaluate function only if not in last iteration\n",
        "        # the reason we do this: in a stochastic setting,\n",
        "        # no use to re-evaluate that function here\n",
        "        f, g = opfunc(x)\n",
        "        lsFuncEval = 1\n",
        "        f_hist.append(f)\n",
        "\n",
        "\n",
        "    # update func eval\n",
        "    currentFuncEval = currentFuncEval + lsFuncEval\n",
        "    state.funcEval = state.funcEval + lsFuncEval\n",
        "\n",
        "    ############################################################\n",
        "    ## check conditions\n",
        "    ############################################################\n",
        "    if nIter == maxIter:\n",
        "      break\n",
        "\n",
        "    if currentFuncEval >= maxEval:\n",
        "      # max nb of function evals\n",
        "      verbose('max nb of function evals')\n",
        "      break\n",
        "\n",
        "    tmp1 = tf.abs(g)\n",
        "    if tf.reduce_sum(tmp1) <=tolFun:\n",
        "      # check optimality\n",
        "      verbose('optimality condition below tolFun')\n",
        "      break\n",
        "    \n",
        "    tmp1 = tf.abs(d*t)\n",
        "    if tf.reduce_sum(tmp1) <= tolX:\n",
        "      # step size below tolX\n",
        "      verbose('step size below tolX')\n",
        "      break\n",
        "\n",
        "    if tf.abs(f-f_old) < tolX:\n",
        "      # function value changing less than tolX\n",
        "      verbose('function value changing less than tolX'+str(tf.abs(f-f_old)))\n",
        "      break\n",
        "\n",
        "    if do_verbose:\n",
        "      log_fn(nIter, f.numpy(), True)\n",
        "      #print(\"Step %3d loss %6.5f msec %6.3f\"%(nIter, f.numpy(), last_time()))\n",
        "      record_time()\n",
        "      times.append(last_time())\n",
        "\n",
        "    if nIter == maxIter - 1:\n",
        "      final_loss = f.numpy()\n",
        "\n",
        "\n",
        "  # save state\n",
        "  state.old_dirs = old_dirs\n",
        "  state.old_stps = old_stps\n",
        "  state.Hdiag = Hdiag\n",
        "  state.g_old = g_old\n",
        "  state.f_old = f_old\n",
        "  state.t = t\n",
        "  state.d = d\n",
        "\n",
        "  return x, f_hist, currentFuncEval\n",
        "\n",
        "# dummy/Struct gives Lua-like struct object with 0 defaults\n",
        "class dummy(object):\n",
        "  pass\n",
        "\n",
        "class Struct(dummy):\n",
        "  def __getattribute__(self, key):\n",
        "    if key == '__dict__':\n",
        "      return super(dummy, self).__getattribute__('__dict__')\n",
        "    return self.__dict__.get(key, 0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yYBxFmN8g58"
      },
      "source": [
        "#%% Utils for Burger's equation\n",
        "\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pyDOE import lhs\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "from scipy.interpolate import griddata\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "# \".\" for Colab/VSCode, and \"..\" for GitHub\n",
        "repoPath = os.path.join(\".\", \"PINNs\")\n",
        "# repoPath = os.path.join(\"..\", \"PINNs\")\n",
        "utilsPath = os.path.join(repoPath, \"Utilities\")\n",
        "dataPath = os.path.join(repoPath, \"main\", \"Data\")\n",
        "appDataPath = os.path.join(repoPath, \"appendix\", \"Data\")\n",
        "\n",
        "sys.path.append(\"utils\")\n",
        "\n",
        "def prep_data(path, N_u=None, N_f=None, N_n=None, q=None, ub=None, lb=None, noise=0.0, idx_t_0=None, idx_t_1=None, N_0=None, N_1=None):\n",
        "    # Reading external data [t is 100x1, usol is 256x100 (solution), x is 256x1]\n",
        "    data = scipy.io.loadmat(path)\n",
        "\n",
        "    # Flatten makes [[]] into [], [:,None] makes it a column vector\n",
        "    t = data['t'].flatten()[:,None] # T x 1\n",
        "    x = data['x'].flatten()[:,None] # N x 1\n",
        "\n",
        "    # Keeping the 2D data for the solution data (real() is maybe to make it float by default, in case of zeroes)\n",
        "    Exact_u = np.real(data['usol']).T # T x N\n",
        "\n",
        "    # x = np.load(\"1d-burgers/data/burgers_x.npy\")[:, None]\n",
        "    # t = np.load(\"1d-burgers/data/burgers_t.npy\")[:, None]\n",
        "    # Exact_u = np.load(\"1d-burgers/data/burgers_u.npy\").T\n",
        "\n",
        "    if N_n != None and q != None and ub != None and lb != None and idx_t_0 != None and idx_t_1 != None:\n",
        "      dt = t[idx_t_1] - t[idx_t_0]\n",
        "      idx_x = np.random.choice(Exact_u.shape[1], N_n, replace=False) \n",
        "      x_0 = x[idx_x,:]\n",
        "      u_0 = Exact_u[idx_t_0:idx_t_0+1,idx_x].T\n",
        "      u_0 = u_0 + noise*np.std(u_0)*np.random.randn(u_0.shape[0], u_0.shape[1])\n",
        "        \n",
        "      # Boudanry data\n",
        "      x_1 = np.vstack((lb, ub))\n",
        "      \n",
        "      # Test data\n",
        "      x_star = x\n",
        "      u_star = Exact_u[idx_t_1,:]\n",
        "\n",
        "      # Load IRK weights\n",
        "      tmp = np.float32(np.loadtxt(os.path.join(utilsPath, \"IRK_weights\", \"Butcher_IRK%d.txt\" % (q)), ndmin = 2))\n",
        "      IRK_weights = np.reshape(tmp[0:q**2+q], (q+1,q))\n",
        "      IRK_times = tmp[q**2+q:]\n",
        "\n",
        "      return x, t, dt, Exact_u, x_0, u_0, x_1, x_star, u_star, IRK_weights, IRK_times\n",
        "\n",
        "    # Meshing x and t in 2D (256,100)\n",
        "    X, T = np.meshgrid(x,t)\n",
        "\n",
        "    # Preparing the inputs x and t (meshed as X, T) for predictions in one single array, as X_star\n",
        "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
        "\n",
        "    # Preparing the testing u_star\n",
        "    u_star = Exact_u.flatten()[:,None]\n",
        "                \n",
        "    # Noiseless data TODO: add support for noisy data    \n",
        "    idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
        "    X_u_train = X_star[idx,:]\n",
        "    u_train = u_star[idx,:]\n",
        "\n",
        "    if N_0 != None and N_1 != None:\n",
        "      Exact_u = Exact_u.T\n",
        "      idx_x = np.random.choice(Exact_u.shape[0], N_0, replace=False)\n",
        "      x_0 = x[idx_x,:]\n",
        "      u_0 = Exact_u[idx_x,idx_t_0][:,None]\n",
        "      u_0 = u_0 + noise*np.std(u_0)*np.random.randn(u_0.shape[0], u_0.shape[1])\n",
        "          \n",
        "      idx_x = np.random.choice(Exact_u.shape[0], N_1, replace=False)\n",
        "      x_1 = x[idx_x,:]\n",
        "      u_1 = Exact_u[idx_x,idx_t_1][:,None]\n",
        "      u_1 = u_1 + noise*np.std(u_1)*np.random.randn(u_1.shape[0], u_1.shape[1])\n",
        "      \n",
        "      dt = np.asscalar(t[idx_t_1] - t[idx_t_0])        \n",
        "      q = int(np.ceil(0.5*np.log(np.finfo(float).eps)/np.log(dt)))\n",
        "\n",
        "      # Load IRK weights\n",
        "      tmp = np.float32(np.loadtxt(os.path.join(utilsPath, \"IRK_weights\", \"Butcher_IRK%d.txt\" % (q)), ndmin = 2))\n",
        "      weights =  np.reshape(tmp[0:q**2+q], (q+1,q))     \n",
        "      IRK_alpha = weights[0:-1,:]\n",
        "      IRK_beta = weights[-1:,:] \n",
        "      return x_0, u_0, x_1, u_1, x, t, dt, q, Exact_u, IRK_alpha, IRK_beta\n",
        "\n",
        "    if N_f == None:\n",
        "      lb = X_star.min(axis=0)\n",
        "      ub = X_star.max(axis=0) \n",
        "      return x, t, X, T, Exact_u, X_star, u_star, X_u_train, u_train, ub, lb\n",
        "\n",
        "    # Domain bounds (lowerbounds upperbounds) [x, t], which are here ([-1.0, 0.0] and [1.0, 1.0])\n",
        "    lb = X_star.min(axis=0)\n",
        "    ub = X_star.max(axis=0) \n",
        "    # Getting the initial conditions (t=0)\n",
        "    xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
        "    uu1 = Exact_u[0:1,:].T\n",
        "    # Getting the lowest boundary conditions (x=-1) \n",
        "    xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
        "    uu2 = Exact_u[:,0:1]\n",
        "    # Getting the highest boundary conditions (x=1) \n",
        "    xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
        "    uu3 = Exact_u[:,-1:]\n",
        "    # Stacking them in multidimensional tensors for training (X_u_train is for now the continuous boundaries)\n",
        "    X_u_train = np.vstack([xx1, xx2, xx3])\n",
        "    u_train = np.vstack([uu1, uu2, uu3])\n",
        "\n",
        "    # Generating the x and t collocation points for f, with each having a N_f size\n",
        "    # We pointwise add and multiply to spread the LHS over the 2D domain\n",
        "    X_f_train = lb + (ub-lb)*lhs(2, N_f)\n",
        "\n",
        "    # Generating a uniform random sample from ints between 0, and the size of x_u_train, of size N_u (initial data size) and without replacement (unique)\n",
        "    idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
        "    # Getting the corresponding X_u_train (which is now scarce boundary/initial coordinates)\n",
        "    X_u_train = X_u_train[idx,:]\n",
        "    # Getting the corresponding u_train\n",
        "    u_train = u_train [idx,:]\n",
        "\n",
        "    return x, t, X, T, Exact_u, X_star, u_star, X_u_train, u_train, X_f_train, ub, lb\n",
        "\n",
        "def plot_inf_cont_results(X_star, u_pred, X_u_train, u_train, Exact_u, X, T, x, t, save_path=None, save_hp=None):\n",
        "\n",
        "  # Interpolating the results on the whole (x,t) domain.\n",
        "  # griddata(points, values, points at which to interpolate, method)\n",
        "  U_pred = griddata(X_star, u_pred, (X, T), method='cubic')\n",
        "\n",
        "  # Creating the figures\n",
        "  fig, ax = newfig(1.0, 1.1)\n",
        "  ax.axis('off')\n",
        "\n",
        "  ####### Row 0: u(t,x) ##################    \n",
        "  gs0 = gridspec.GridSpec(1, 2)\n",
        "  gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
        "  ax = plt.subplot(gs0[:, :])\n",
        "\n",
        "  h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
        "                origin='lower', aspect='auto')\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  fig.colorbar(h, cax=cax)\n",
        "\n",
        "  ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 4, clip_on = False)\n",
        "\n",
        "  line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "  ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)    \n",
        "\n",
        "  ax.set_xlabel('$t$')\n",
        "  ax.set_ylabel('$x$')\n",
        "  ax.legend(frameon=False, loc = 'best')\n",
        "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "\n",
        "  ####### Row 1: u(t,x) slices ##################    \n",
        "  gs1 = gridspec.GridSpec(1, 3)\n",
        "  gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5)\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 0])\n",
        "  ax.plot(x,Exact_u[25,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "  ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')    \n",
        "  ax.set_title('$t = 0.25$', fontsize = 10)\n",
        "  ax.axis('square')\n",
        "  ax.set_xlim([-1.1,1.1])\n",
        "  ax.set_ylim([-1.1,1.1])\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 1])\n",
        "  ax.plot(x,Exact_u[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "  ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.axis('square')\n",
        "  ax.set_xlim([-1.1,1.1])\n",
        "  ax.set_ylim([-1.1,1.1])\n",
        "  ax.set_title('$t = 0.50$', fontsize = 10)\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 2])\n",
        "  ax.plot(x,Exact_u[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "  ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.axis('square')\n",
        "  ax.set_xlim([-1.1,1.1])\n",
        "  ax.set_ylim([-1.1,1.1])    \n",
        "  ax.set_title('$t = 0.75$', fontsize = 10)\n",
        "\n",
        "  if save_path != None and save_hp != None:\n",
        "      saveResultDir(save_path, save_hp)\n",
        "\n",
        "  else:\n",
        "    plt.show()\n",
        "\n",
        "def plot_inf_disc_results(x_star, idx_t_0, idx_t_1, x_0, u_0, ub, lb, u_1_pred, Exact_u, x, t, save_path=None, save_hp=None):\n",
        "  fig, ax = newfig(1.0, 1.2)\n",
        "  ax.axis('off')\n",
        "  \n",
        "  ####### Row 0: h(t,x) ##################    \n",
        "  gs0 = gridspec.GridSpec(1, 2)\n",
        "  gs0.update(top=1-0.06, bottom=1-1/2 + 0.1, left=0.15, right=0.85, wspace=0)\n",
        "  ax = plt.subplot(gs0[:, :])\n",
        "  \n",
        "  h = ax.imshow(Exact_u.T, interpolation='nearest', cmap='rainbow', \n",
        "                extent=[t.min(), t.max(), x_star.min(), x_star.max()], \n",
        "                origin='lower', aspect='auto')\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  fig.colorbar(h, cax=cax)\n",
        "      \n",
        "  line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "  ax.plot(t[idx_t_0]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  ax.plot(t[idx_t_1]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  \n",
        "  ax.set_xlabel('$t$')\n",
        "  ax.set_ylabel('$x$')\n",
        "  leg = ax.legend(frameon=False, loc = 'best')\n",
        "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "  \n",
        "  \n",
        "  ####### Row 1: h(t,x) slices ##################    \n",
        "  gs1 = gridspec.GridSpec(1, 2)\n",
        "  gs1.update(top=1-1/2-0.05, bottom=0.15, left=0.15, right=0.85, wspace=0.5)\n",
        "  \n",
        "  ax = plt.subplot(gs1[0, 0])\n",
        "  ax.plot(x,Exact_u[idx_t_0,:], 'b-', linewidth = 2) \n",
        "  ax.plot(x_0, u_0, 'rx', linewidth = 2, label = 'Data')      \n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')    \n",
        "  ax.set_title('$t = %.2f$' % (t[idx_t_0]), fontsize = 10)\n",
        "  ax.set_xlim([lb-0.1, ub+0.1])\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.8, -0.3), ncol=2, frameon=False)\n",
        "\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 1])\n",
        "  ax.plot(x, Exact_u[idx_t_1,:], 'b-', linewidth = 2, label = 'Exact') \n",
        "  ax.plot(x_star, u_1_pred, 'r--', linewidth = 2, label = 'Prediction')      \n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')    \n",
        "  ax.set_title('$t = %.2f$' % (t[idx_t_1]), fontsize = 10)    \n",
        "  ax.set_xlim([lb-0.1, ub+0.1])\n",
        "  \n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.1, -0.3), ncol=2, frameon=False)\n",
        "\n",
        "  if save_path != None and save_hp != None:\n",
        "      saveResultDir(save_path, save_hp)\n",
        "\n",
        "  else:\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_ide_disc_results(x_star, t_star, idx_t_0, idx_t_1, x_0, u_0, x_1, u_1,\n",
        "  ub, lb, u_1_pred, Exact, lambda_1_value, lambda_1_value_noisy, lambda_2_value, lambda_2_value_noisy,\n",
        "  x, t, save_path=None, save_hp=None):  \n",
        "  fig, ax = newfig(1.0, 1.5)\n",
        "  ax.axis('off')\n",
        "  \n",
        "  gs0 = gridspec.GridSpec(1, 2)\n",
        "  gs0.update(top=1-0.06, bottom=1-1/3+0.05, left=0.15, right=0.85, wspace=0)\n",
        "  ax = plt.subplot(gs0[:, :])\n",
        "      \n",
        "  h = ax.imshow(Exact, interpolation='nearest', cmap='rainbow',\n",
        "                extent=[t_star.min(),t_star.max(), lb[0], ub[0]],\n",
        "                origin='lower', aspect='auto')\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  fig.colorbar(h, cax=cax)\n",
        "  \n",
        "  line = np.linspace(x_star.min(), x_star.max(), 2)[:,None]\n",
        "  ax.plot(t_star[idx_t_0]*np.ones((2,1)), line, 'w-', linewidth = 1.0)\n",
        "  ax.plot(t_star[idx_t_1]*np.ones((2,1)), line, 'w-', linewidth = 1.0)    \n",
        "  ax.set_xlabel('$t$')\n",
        "  ax.set_ylabel('$x$')\n",
        "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "  \n",
        "  gs1 = gridspec.GridSpec(1, 2)\n",
        "  gs1.update(top=1-1/3-0.1, bottom=1-2/3, left=0.15, right=0.85, wspace=0.5)\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 0])\n",
        "  ax.plot(x_star,Exact[:,idx_t_0][:,None], 'b', linewidth = 2, label = 'Exact')\n",
        "  ax.plot(x_0, u_0, 'rx', linewidth = 2, label = 'Data')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.set_title('$t = %.2f$\\n%d trainng data' % (t_star[idx_t_0], u_0.shape[0]), fontsize = 10)\n",
        "  \n",
        "  ax = plt.subplot(gs1[0, 1])\n",
        "  ax.plot(x_star,Exact[:,idx_t_1][:,None], 'b', linewidth = 2, label = 'Exact')\n",
        "  ax.plot(x_1, u_1, 'rx', linewidth = 2, label = 'Data')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.set_title('$t = %.2f$\\n%d trainng data' % (t_star[idx_t_1], u_1.shape[0]), fontsize = 10)\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(-0.3, -0.3), ncol=2, frameon=False)\n",
        "  \n",
        "  gs2 = gridspec.GridSpec(1, 2)\n",
        "  gs2.update(top=1-2/3-0.05, bottom=0, left=0.15, right=0.85, wspace=0.0)\n",
        "  \n",
        "  ax = plt.subplot(gs2[0, 0])\n",
        "  ax.axis('off')\n",
        "  nu = 0.01/np.pi\n",
        "  s1 = r'$\\begin{tabular}{ |c|c| }  \\hline Correct PDE & $u_t + u u_x + %.6f u_{xx} = 0$ \\\\  \\hline Identified PDE (clean data) & ' % (nu)\n",
        "  s2 = r'$u_t + %.3f u u_x + %.6f u_{xx} = 0$ \\\\  \\hline ' % (lambda_1_value, lambda_2_value)\n",
        "  s3 = r'Identified PDE (1\\% noise) & '\n",
        "  s4 = r'$u_t + %.3f u u_x + %.6f u_{xx} = 0$  \\\\  \\hline ' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "  s5 = r'\\end{tabular}$'\n",
        "  s = s1+s2+s3+s4+s5\n",
        "  ax.text(-0.1,0.2,s)\n",
        "\n",
        "  if save_path != None and save_hp != None:\n",
        "      saveResultDir(save_path, save_hp)\n",
        "\n",
        "  else:\n",
        "    plt.show()\n",
        "\n",
        "def plot_ide_cont_results(X_star, u_pred, X_u_train, u_train,\n",
        "  Exact_u, X, T, x, t, lambda_1_value, lambda_1_value_noisy, lambda_2_value, lambda_2_value_noisy):\n",
        "    fig, ax = newfig(1.0, 1.4)\n",
        "    ax.axis('off')\n",
        "\n",
        "    U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
        "    \n",
        "    ####### Row 0: u(t,x) ##################    \n",
        "    gs0 = gridspec.GridSpec(1, 2)\n",
        "    gs0.update(top=1-0.06, bottom=1-1.0/3.0+0.06, left=0.15, right=0.85, wspace=0)\n",
        "    ax = plt.subplot(gs0[:, :])\n",
        "    \n",
        "    h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "                  extent=[t.min(), t.max(), x.min(), x.max()], \n",
        "                  origin='lower', aspect='auto')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    fig.colorbar(h, cax=cax)\n",
        "    \n",
        "    ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 2, clip_on = False)\n",
        "    \n",
        "    line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "    ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    \n",
        "    ax.set_xlabel('$t$')\n",
        "    ax.set_ylabel('$x$')\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(1.0, -0.125), ncol=5, frameon=False)\n",
        "    ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "    \n",
        "    ####### Row 1: u(t,x) slices ##################    \n",
        "    gs1 = gridspec.GridSpec(1, 3)\n",
        "    gs1.update(top=1-1.0/3.0-0.1, bottom=1.0-2.0/3.0, left=0.1, right=0.9, wspace=0.5)\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 0])\n",
        "    ax.plot(x,Exact_u[25,:], 'b-', linewidth = 2, label = 'Exact')\n",
        "    ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')    \n",
        "    ax.set_title('$t = 0.25$', fontsize = 10)\n",
        "    ax.axis('square')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 1])\n",
        "    ax.plot(x,Exact_u[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "    ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')\n",
        "    ax.axis('square')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])\n",
        "    ax.set_title('$t = 0.50$', fontsize = 10)\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 2])\n",
        "    ax.plot(x,Exact_u[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "    ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')\n",
        "    ax.axis('square')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])    \n",
        "    ax.set_title('$t = 0.75$', fontsize = 10)\n",
        "    \n",
        "    ####### Row 3: Identified PDE ##################    \n",
        "    gs2 = gridspec.GridSpec(1, 3)\n",
        "    gs2.update(top=1.0-2.0/3.0, bottom=0, left=0.0, right=1.0, wspace=0.0)\n",
        "    \n",
        "    ax = plt.subplot(gs2[:, :])\n",
        "    ax.axis('off')\n",
        "    s1 = r'$\\begin{tabular}{ |c|c| }  \\hline Correct PDE & $u_t + u u_x - 0.0031831 u_{xx} = 0$ \\\\  \\hline Identified PDE (clean data) & '\n",
        "    s2 = r'$u_t + %.5f u u_x - %.7f u_{xx} = 0$ \\\\  \\hline ' % (lambda_1_value, lambda_2_value)\n",
        "    s3 = r'Identified PDE (1\\% noise) & '\n",
        "    s4 = r'$u_t + %.5f u u_x - %.7f u_{xx} = 0$  \\\\  \\hline ' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "    s5 = r'\\end{tabular}$'\n",
        "    s = s1+s2+s3+s4+s5\n",
        "    ax.text(0.1,0.1,s)\n",
        "    plt.show()\n",
        "    savefig('./content/Burgers_identification')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2CZd9yt_rot"
      },
      "source": [
        "# RUnning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uz8YCt1hn2O",
        "outputId": "d351caf4-efa1-4bf0-ea79-3272c50cbe4c"
      },
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "# Manually making sure the numpy random seeds are \"the same\" on all devices\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "# HYPER PARAMETERS\n",
        "\n",
        "\n",
        "hp = {}\n",
        "# Data size on the solution u\n",
        "hp[\"N_u\"] = 100\n",
        "# Collocation points size, where we’ll check for f = 0\n",
        "hp[\"N_f\"] = 10000\n",
        "# DeepNN topology (2-sized input [x t], 8 hidden layer of 20-width, 1-sized output [u]\n",
        "hp[\"layers\"] = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
        "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
        "hp[\"tf_epochs\"] = 120\n",
        "hp[\"tf_lr\"] = 0.03\n",
        "hp[\"tf_b1\"] = 0.9\n",
        "hp[\"tf_eps\"] = None\n",
        "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
        "hp[\"nt_epochs\"] = 500\n",
        "hp[\"nt_lr\"] = 0.8\n",
        "hp[\"nt_ncorr\"] = 50\n",
        "hp[\"log_frequency\"] = 10\n",
        "\n",
        "# %% DEFINING THE MODEL\n",
        "\n",
        "\n",
        "class BurgersInformedNN(NeuralNetwork):\n",
        "    def __init__(self, hp, logger, X_f, ub, lb, nu):\n",
        "        super().__init__(hp, logger, ub, lb)\n",
        "\n",
        "        self.nu = nu\n",
        "\n",
        "        # Separating the collocation coordinates\n",
        "        self.x_f = self.tensor(X_f[:, 0:1])\n",
        "        self.t_f = self.tensor(X_f[:, 1:2])\n",
        "\n",
        "    # Defining custom loss\n",
        "    def loss(self, u, u_pred):\n",
        "        f_pred = self.f_model()\n",
        "        return tf.reduce_mean(tf.square(u - u_pred)) + \\\n",
        "            tf.reduce_mean(tf.square(f_pred))\n",
        "\n",
        "    # The actual PINN\n",
        "    def f_model(self):\n",
        "        # Using the new GradientTape paradigm of TF2.0,\n",
        "        # which keeps track of operations to get the gradient at runtime\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # Watching the two inputs we’ll need later, x and t\n",
        "            tape.watch(self.x_f)\n",
        "            tape.watch(self.t_f)\n",
        "            # Packing together the inputs\n",
        "            X_f = tf.stack([self.x_f[:, 0], self.t_f[:, 0]], axis=1)\n",
        "\n",
        "            # Getting the prediction\n",
        "            u = self.model(X_f)\n",
        "            # Deriving INSIDE the tape (since we’ll need the x derivative of this later, u_xx)\n",
        "            u_x = tape.gradient(u, self.x_f)\n",
        "\n",
        "        # Getting the other derivatives\n",
        "        u_xx = tape.gradient(u_x, self.x_f)\n",
        "        u_t = tape.gradient(u, self.t_f)\n",
        "\n",
        "        # Letting the tape go\n",
        "        del tape\n",
        "\n",
        "        nu = self.get_params(numpy=True)\n",
        "\n",
        "        # Buidling the PINNs\n",
        "        return u_t + u*u_x - nu*u_xx\n",
        "\n",
        "    def get_params(self, numpy=False):\n",
        "        return self.nu\n",
        "\n",
        "    def predict(self, X_star):\n",
        "        u_star = self.model(X_star)\n",
        "        f_star = self.f_model()\n",
        "        return u_star.numpy(), f_star.numpy()\n",
        "\n",
        "# %% TRAINING THE MODEL\n",
        "\n",
        "\n",
        "# Getting the data\n",
        "path = os.path.join(\"/content/drive/MyDrive/PINNs-TF2.0/1d-burgers/data\", \"burgers_shock.mat\")\n",
        "x, t, X, T, Exact_u, X_star, u_star, \\\n",
        "    X_u_train, u_train, X_f, ub, lb = prep_data(\n",
        "        path, hp[\"N_u\"], hp[\"N_f\"], noise=0.0)\n",
        "\n",
        "# Creating the model\n",
        "logger = Logger(hp)\n",
        "pinn = BurgersInformedNN(hp, logger, X_f, ub, lb, nu=0.01/np.pi)\n",
        "\n",
        "# Defining the error function for the logger and training\n",
        "def error():\n",
        "    u_pred, _ = pinn.predict(X_star)\n",
        "    return np.linalg.norm(u_star - u_pred, 2) / np.linalg.norm(u_star, 2)\n",
        "\n",
        "\n",
        "logger.set_error_fn(error)\n",
        "pinn.fit(X_u_train, u_train)\n",
        "\n",
        "# Getting the model predictions\n",
        "u_pred, _ = pinn.predict(X_star)\n",
        "\n",
        "\n",
        "# %% PLOTTING\n",
        "plot_inf_cont_results(X_star, u_pred.flatten(), X_u_train, u_train,\n",
        "                      Exact_u, X, T, x, t)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyperparameters:\n",
            "{\n",
            "  \"N_u\": 100,\n",
            "  \"N_f\": 10000,\n",
            "  \"layers\": [\n",
            "    2,\n",
            "    20,\n",
            "    20,\n",
            "    20,\n",
            "    20,\n",
            "    20,\n",
            "    20,\n",
            "    20,\n",
            "    20,\n",
            "    1\n",
            "  ],\n",
            "  \"tf_epochs\": 120,\n",
            "  \"tf_lr\": 0.03,\n",
            "  \"tf_b1\": 0.9,\n",
            "  \"tf_eps\": null,\n",
            "  \"nt_epochs\": 500,\n",
            "  \"nt_lr\": 0.8,\n",
            "  \"nt_ncorr\": 50,\n",
            "  \"log_frequency\": 10\n",
            "}\n",
            "\n",
            "TensorFlow version: 2.4.1\n",
            "Eager execution: True\n",
            "GPU-accerelated: True\n",
            "\n",
            "Training started\n",
            "================\n",
            "-- Starting Adam optimization --\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "tf_epoch =      0  elapsed = 00:00 (+00.1)  loss = 2.4713e-01  \n",
            "tf_epoch =     10  elapsed = 00:00 (+00.6)  loss = 2.6044e-01  \n",
            "tf_epoch =     20  elapsed = 00:01 (+00.6)  loss = 1.6198e-01  \n",
            "tf_epoch =     30  elapsed = 00:02 (+00.6)  loss = 1.2458e-01  \n",
            "tf_epoch =     40  elapsed = 00:02 (+00.6)  loss = 1.0602e-01  \n",
            "tf_epoch =     50  elapsed = 00:03 (+00.6)  loss = 8.9587e-02  \n",
            "tf_epoch =     60  elapsed = 00:04 (+00.6)  loss = 7.5692e-02  \n",
            "tf_epoch =     70  elapsed = 00:04 (+00.6)  loss = 6.7965e-02  \n",
            "tf_epoch =     80  elapsed = 00:05 (+00.6)  loss = 6.2576e-02  \n",
            "tf_epoch =     90  elapsed = 00:06 (+00.6)  loss = 6.0161e-02  \n",
            "tf_epoch =    100  elapsed = 00:06 (+00.6)  loss = 9.9555e-02  \n",
            "tf_epoch =    110  elapsed = 00:07 (+00.6)  loss = 8.0400e-02  \n",
            "-- Starting LBFGS optimization --\n",
            "nt_epoch =     10  elapsed = 00:09 (+01.5)  loss = 5.7271e-02  \n",
            "nt_epoch =     20  elapsed = 00:09 (+00.9)  loss = 5.3729e-02  \n",
            "nt_epoch =     30  elapsed = 00:10 (+01.0)  loss = 4.6764e-02  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLL85HUR_otN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}