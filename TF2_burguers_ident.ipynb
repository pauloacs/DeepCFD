{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF2_burguers_ident.ipynb",
      "provenance": [],
      "mount_file_id": "1p2QAEGT6uVtKq9w6GhZ38yd0VgsREGyb",
      "authorship_tag": "ABX9TyN4fag5QT/lxQWpcs+ZM3AP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pauloacs/DeepCFD/blob/main/TF2_burguers_ident.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDPHl8PZHsbz"
      },
      "source": [
        "# Installing **latex** & pyDOE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m11J46MtBwJO",
        "outputId": "898bc7af-7785-439c-e718-5bcaeb30bb65"
      },
      "source": [
        "! sudo apt-get install texlive-latex-recommended \n",
        "! sudo apt-get install dvipng texlive-latex-extra texlive-fonts-recommended  \n",
        "! wget http://mirrors.ctan.org/macros/latex/contrib/type1cm.zip \n",
        "! unzip type1cm.zip -d /tmp/type1cm \n",
        "! cd /tmp/type1cm/type1cm/ && sudo latex type1cm.ins\n",
        "! sudo mkdir /usr/share/texmf/tex/latex/type1cm \n",
        "! sudo cp /tmp/type1cm/type1cm/type1cm.sty /usr/share/texmf/tex/latex/type1cm \n",
        "! sudo texhash \n",
        "!apt install cm-super\n",
        "!pip install --upgrade pyDOE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-lmodern fonts-noto-mono libcupsfilters1\n",
            "  libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0 libkpathsea6\n",
            "  libpotrace0 libptexenc1 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13\n",
            "  lmodern poppler-data t1utils tex-common texlive-base texlive-binaries\n",
            "  texlive-latex-base\n",
            "Suggested packages:\n",
            "  fonts-noto poppler-utils ghostscript fonts-japanese-mincho\n",
            "  | fonts-ipafont-mincho fonts-japanese-gothic | fonts-ipafont-gothic\n",
            "  fonts-arphic-ukai fonts-arphic-uming fonts-nanum debhelper gv\n",
            "  | postscript-viewer perl-tk xpdf-reader | pdf-viewer texlive-latex-base-doc\n",
            "  texlive-latex-recommended-doc texlive-pstricks\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-lmodern fonts-noto-mono libcupsfilters1\n",
            "  libcupsimage2 libgs9 libgs9-common libijs-0.35 libjbig2dec0 libkpathsea6\n",
            "  libpotrace0 libptexenc1 libsynctex1 libtexlua52 libtexluajit2 libzzip-0-13\n",
            "  lmodern poppler-data t1utils tex-common texlive-base texlive-binaries\n",
            "  texlive-latex-base texlive-latex-recommended\n",
            "0 upgraded, 24 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 68.4 MB of archives.\n",
            "After this operation, 223 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 poppler-data all 0.4.8-2 [1,479 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 tex-common all 6.09 [33.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lmodern all 2.004.5-3 [4,551 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-noto-mono all 20171026-2 [75.5 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsfilters1 amd64 1.20.2-0ubuntu3.1 [108 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libcupsimage2 amd64 2.2.7-1ubuntu2.8 [18.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libijs-0.35 amd64 0.35-13 [15.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjbig2dec0 amd64 0.13-6 [55.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9-common all 9.26~dfsg+0-0ubuntu0.18.04.14 [5,092 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgs9 amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [2,265 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libkpathsea6 amd64 2017.20170613.44572-8ubuntu0.1 [54.9 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpotrace0 amd64 1.14-2 [17.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libptexenc1 amd64 2017.20170613.44572-8ubuntu0.1 [34.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libsynctex1 amd64 2017.20170613.44572-8ubuntu0.1 [41.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexlua52 amd64 2017.20170613.44572-8ubuntu0.1 [91.2 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libtexluajit2 amd64 2017.20170613.44572-8ubuntu0.1 [230 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libzzip-0-13 amd64 0.13.62-3.1ubuntu0.18.04.1 [26.0 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 lmodern all 2.004.5-3 [9,631 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 t1utils amd64 1.41-2 [56.0 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 texlive-binaries amd64 2017.20170613.44572-8ubuntu0.1 [8,179 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-base all 2017.20180305-1 [18.7 MB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-base all 2017.20180305-1 [951 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/main amd64 texlive-latex-recommended all 2017.20180305-1 [14.9 MB]\n",
            "Fetched 68.4 MB in 3s (26.8 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 24.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 146442 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../01-poppler-data_0.4.8-2_all.deb ...\n",
            "Unpacking poppler-data (0.4.8-2) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../02-tex-common_6.09_all.deb ...\n",
            "Unpacking tex-common (6.09) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../03-fonts-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../04-fonts-noto-mono_20171026-2_all.deb ...\n",
            "Unpacking fonts-noto-mono (20171026-2) ...\n",
            "Selecting previously unselected package libcupsfilters1:amd64.\n",
            "Preparing to unpack .../05-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n",
            "Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Selecting previously unselected package libcupsimage2:amd64.\n",
            "Preparing to unpack .../06-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n",
            "Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../07-libijs-0.35_0.35-13_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-13) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../08-libjbig2dec0_0.13-6_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.13-6) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.14_all.deb ...\n",
            "Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../10-libgs9_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../11-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libpotrace0.\n",
            "Preparing to unpack .../12-libpotrace0_1.14-2_amd64.deb ...\n",
            "Unpacking libpotrace0 (1.14-2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../13-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libsynctex1:amd64.\n",
            "Preparing to unpack .../14-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexlua52:amd64.\n",
            "Preparing to unpack .../15-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../16-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../17-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../18-lmodern_2.004.5-3_all.deb ...\n",
            "Unpacking lmodern (2.004.5-3) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../19-t1utils_1.41-2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-2) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../20-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n",
            "Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../21-texlive-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../22-texlive-latex-base_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../23-texlive-latex-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2017.20180305-1) ...\n",
            "Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n",
            "Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up poppler-data (0.4.8-2) ...\n",
            "Setting up fonts-noto-mono (20171026-2) ...\n",
            "Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n",
            "Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n",
            "Setting up libjbig2dec0:amd64 (0.13-6) ...\n",
            "Setting up t1utils (1.41-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-13) ...\n",
            "Setting up libpotrace0 (1.14-2) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n",
            "Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n",
            "Setting up fonts-lmodern (2.004.5-3) ...\n",
            "Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up texlive-base (2017.20180305-1) ...\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Setting up texlive-latex-base (2017.20180305-1) ...\n",
            "Setting up lmodern (2.004.5-3) ...\n",
            "Setting up texlive-latex-recommended (2017.20180305-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-lato fonts-texgyre ghostscript gsfonts javascript-common libjs-jquery\n",
            "  libruby2.5 preview-latex-style rake ruby ruby-did-you-mean ruby-minitest\n",
            "  ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration tex-gyre texlive-pictures texlive-plain-generic tipa\n",
            "Suggested packages:\n",
            "  ghostscript-x apache2 | lighttpd | httpd ri ruby-dev bundler\n",
            "  texlive-fonts-recommended-doc python-pygments icc-profiles\n",
            "  libfile-which-perl libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  dot2tex prerex ruby-tcltk | libtcltk-ruby texlive-pictures-doc vprerex\n",
            "The following NEW packages will be installed:\n",
            "  dvipng fonts-lato fonts-texgyre ghostscript gsfonts javascript-common\n",
            "  libjs-jquery libruby2.5 preview-latex-style rake ruby ruby-did-you-mean\n",
            "  ruby-minitest ruby-net-telnet ruby-power-assert ruby-test-unit ruby2.5\n",
            "  rubygems-integration tex-gyre texlive-fonts-recommended texlive-latex-extra\n",
            "  texlive-pictures texlive-plain-generic tipa\n",
            "0 upgraded, 24 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 69.8 MB of archives.\n",
            "After this operation, 221 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lato all 2.0-2 [2,698 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ghostscript amd64 9.26~dfsg+0-0ubuntu0.18.04.14 [51.3 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 dvipng amd64 1.15-1 [78.2 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-texgyre all 20160520-1 [8,761 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.4 [3,120 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 javascript-common all 11 [6,066 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libjs-jquery all 3.2.1-1 [152 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 rubygems-integration all 1.11 [4,994 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 ruby2.5 amd64 2.5.1-1ubuntu1.7 [48.6 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby amd64 1:2.5.1 [5,712 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 rake all 12.3.1-1ubuntu0.1 [44.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-did-you-mean all 1.2.0-2 [9,700 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-minitest all 5.10.3-1 [38.6 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-power-assert all 0.3.0-1 [7,952 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 ruby-test-unit all 3.2.5-1 [61.1 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libruby2.5 amd64 2.5.1-1ubuntu1.7 [3,068 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic/main amd64 preview-latex-style all 11.91-1ubuntu1 [185 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tex-gyre all 20160520-1 [4,998 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-fonts-recommended all 2017.20180305-1 [5,262 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-pictures all 2017.20180305-1 [4,026 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-latex-extra all 2017.20180305-2 [10.6 MB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic/universe amd64 texlive-plain-generic all 2017.20180305-2 [23.6 MB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tipa all 2:1.3-20 [2,978 kB]\n",
            "Fetched 69.8 MB in 3s (26.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 24.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-lato.\n",
            "(Reading database ... 153776 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-lato_2.0-2_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../01-ghostscript_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n",
            "Unpacking ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Selecting previously unselected package dvipng.\n",
            "Preparing to unpack .../02-dvipng_1.15-1_amd64.deb ...\n",
            "Unpacking dvipng (1.15-1) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../03-fonts-texgyre_20160520-1_all.deb ...\n",
            "Unpacking fonts-texgyre (20160520-1) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../04-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.4_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../05-javascript-common_11_all.deb ...\n",
            "Unpacking javascript-common (11) ...\n",
            "Selecting previously unselected package libjs-jquery.\n",
            "Preparing to unpack .../06-libjs-jquery_3.2.1-1_all.deb ...\n",
            "Unpacking libjs-jquery (3.2.1-1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../07-rubygems-integration_1.11_all.deb ...\n",
            "Unpacking rubygems-integration (1.11) ...\n",
            "Selecting previously unselected package ruby2.5.\n",
            "Preparing to unpack .../08-ruby2.5_2.5.1-1ubuntu1.7_amd64.deb ...\n",
            "Unpacking ruby2.5 (2.5.1-1ubuntu1.7) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../09-ruby_1%3a2.5.1_amd64.deb ...\n",
            "Unpacking ruby (1:2.5.1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../10-rake_12.3.1-1ubuntu0.1_all.deb ...\n",
            "Unpacking rake (12.3.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-did-you-mean.\n",
            "Preparing to unpack .../11-ruby-did-you-mean_1.2.0-2_all.deb ...\n",
            "Unpacking ruby-did-you-mean (1.2.0-2) ...\n",
            "Selecting previously unselected package ruby-minitest.\n",
            "Preparing to unpack .../12-ruby-minitest_5.10.3-1_all.deb ...\n",
            "Unpacking ruby-minitest (5.10.3-1) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../13-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-power-assert.\n",
            "Preparing to unpack .../14-ruby-power-assert_0.3.0-1_all.deb ...\n",
            "Unpacking ruby-power-assert (0.3.0-1) ...\n",
            "Selecting previously unselected package ruby-test-unit.\n",
            "Preparing to unpack .../15-ruby-test-unit_3.2.5-1_all.deb ...\n",
            "Unpacking ruby-test-unit (3.2.5-1) ...\n",
            "Selecting previously unselected package libruby2.5:amd64.\n",
            "Preparing to unpack .../16-libruby2.5_2.5.1-1ubuntu1.7_amd64.deb ...\n",
            "Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.7) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../17-preview-latex-style_11.91-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (11.91-1ubuntu1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../18-tex-gyre_20160520-1_all.deb ...\n",
            "Unpacking tex-gyre (20160520-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../19-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../20-texlive-pictures_2017.20180305-1_all.deb ...\n",
            "Unpacking texlive-pictures (2017.20180305-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../21-texlive-latex-extra_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-latex-extra (2017.20180305-2) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../22-texlive-plain-generic_2017.20180305-2_all.deb ...\n",
            "Unpacking texlive-plain-generic (2017.20180305-2) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../23-tipa_2%3a1.3-20_all.deb ...\n",
            "Unpacking tipa (2:1.3-20) ...\n",
            "Setting up libjs-jquery (3.2.1-1) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.4) ...\n",
            "Setting up texlive-pictures (2017.20180305-1) ...\n",
            "Setting up tex-gyre (20160520-1) ...\n",
            "Setting up tipa (2:1.3-20) ...\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-DEBIAN'... done.\n",
            "Regenerating '/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST'... done.\n",
            "update-fmtutil has updated the following file(s):\n",
            "\t/var/lib/texmf/fmtutil.cnf-DEBIAN\n",
            "\t/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST\n",
            "If you want to activate the changes in the above file(s),\n",
            "you should run fmtutil-sys or fmtutil.\n",
            "Setting up preview-latex-style (11.91-1ubuntu1) ...\n",
            "Setting up ghostscript (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n",
            "Setting up fonts-texgyre (20160520-1) ...\n",
            "Setting up fonts-lato (2.0-2) ...\n",
            "Setting up ruby-did-you-mean (1.2.0-2) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up rubygems-integration (1.11) ...\n",
            "Setting up javascript-common (11) ...\n",
            "Setting up texlive-fonts-recommended (2017.20180305-1) ...\n",
            "Setting up texlive-plain-generic (2017.20180305-2) ...\n",
            "Setting up ruby-minitest (5.10.3-1) ...\n",
            "Setting up ruby-power-assert (0.3.0-1) ...\n",
            "Setting up texlive-latex-extra (2017.20180305-2) ...\n",
            "Setting up dvipng (1.15-1) ...\n",
            "Setting up rake (12.3.1-1ubuntu0.1) ...\n",
            "Setting up ruby2.5 (2.5.1-1ubuntu1.7) ...\n",
            "Setting up ruby (1:2.5.1) ...\n",
            "Setting up ruby-test-unit (3.2.5-1) ...\n",
            "Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.7) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Running mktexlsr. This may take some time... done.\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "--2021-02-21 19:43:48--  http://mirrors.ctan.org/macros/latex/contrib/type1cm.zip\n",
            "Resolving mirrors.ctan.org (mirrors.ctan.org)... 5.35.249.60\n",
            "Connecting to mirrors.ctan.org (mirrors.ctan.org)|5.35.249.60|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://ctan.math.washington.edu/tex-archive/macros/latex/contrib/type1cm.zip [following]\n",
            "--2021-02-21 19:43:49--  http://ctan.math.washington.edu/tex-archive/macros/latex/contrib/type1cm.zip\n",
            "Resolving ctan.math.washington.edu (ctan.math.washington.edu)... 128.95.224.254\n",
            "Connecting to ctan.math.washington.edu (ctan.math.washington.edu)|128.95.224.254|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 328566 (321K) [application/zip]\n",
            "Saving to: ‘type1cm.zip’\n",
            "\n",
            "type1cm.zip         100%[===================>] 320.87K   166 B/s    in 6.3s    \n",
            "\n",
            "2021-02-21 19:43:56 (50.9 KB/s) - ‘type1cm.zip’ saved [328566/328566]\n",
            "\n",
            "Archive:  type1cm.zip\n",
            "   creating: /tmp/type1cm/type1cm/\n",
            "  inflating: /tmp/type1cm/type1cm/type1cm.fdd  \n",
            "  inflating: /tmp/type1cm/type1cm/type1cm.ins  \n",
            "  inflating: /tmp/type1cm/type1cm/type1cm.txt  \n",
            "  inflating: /tmp/type1cm/type1cm/type1cm-doc.pdf  \n",
            "  inflating: /tmp/type1cm/type1cm/type1cm-doc.tex  \n",
            "This is pdfTeX, Version 3.14159265-2.6-1.40.18 (TeX Live 2017/Debian) (preloaded format=latex)\n",
            " restricted \\write18 enabled.\n",
            "entering extended mode\n",
            "(./type1cm.ins\n",
            "LaTeX2e <2017-04-15>\n",
            "Babel <3.18> and hyphenation patterns for 3 language(s) loaded.\n",
            "(/usr/share/texlive/texmf-dist/tex/latex/base/docstrip.tex\n",
            "Utility: `docstrip' 2.5e <2014/09/29>\n",
            "English documentation    <2017/03/13>\n",
            "\n",
            "**********************************************************\n",
            "* This program converts documented macro-files into fast *\n",
            "* loadable files by stripping off (nearly) all comments! *\n",
            "**********************************************************\n",
            "\n",
            "********************************************************\n",
            "* No Configuration file found, using default settings. *\n",
            "********************************************************\n",
            "\n",
            "(./type1cm.ins\n",
            "\n",
            "Generating file(s) ./type1cm.sty \n",
            "\n",
            "Processing file type1cm.fdd (package,ams) -> type1cm.sty\n",
            "Lines  processed: 410\n",
            "Comments removed: 25\n",
            "Comments  passed: 7\n",
            "Codelines passed: 263\n",
            "\n",
            ") ) )\n",
            "No pages of output.\n",
            "Transcript written on type1cm.log.\n",
            "texhash: Updating /usr/local/share/texmf/ls-R... \n",
            "texhash: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "texhash: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "texhash: Updating /var/lib/texmf/ls-R... \n",
            "texhash: Done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cm-super-minimal pfb2t1c2pfb\n",
            "The following NEW packages will be installed:\n",
            "  cm-super cm-super-minimal pfb2t1c2pfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 10 not upgraded.\n",
            "Need to get 24.5 MB of archives.\n",
            "After this operation, 59.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super-minimal all 0.3.4-11 [5,810 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 pfb2t1c2pfb amd64 0.3-11 [9,342 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cm-super all 0.3.4-11 [18.7 MB]\n",
            "Fetched 24.5 MB in 1s (17.9 MB/s)\n",
            "Selecting previously unselected package cm-super-minimal.\n",
            "(Reading database ... 172320 files and directories currently installed.)\n",
            "Preparing to unpack .../cm-super-minimal_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super-minimal (0.3.4-11) ...\n",
            "Selecting previously unselected package pfb2t1c2pfb.\n",
            "Preparing to unpack .../pfb2t1c2pfb_0.3-11_amd64.deb ...\n",
            "Unpacking pfb2t1c2pfb (0.3-11) ...\n",
            "Selecting previously unselected package cm-super.\n",
            "Preparing to unpack .../cm-super_0.3.4-11_all.deb ...\n",
            "Unpacking cm-super (0.3.4-11) ...\n",
            "Setting up pfb2t1c2pfb (0.3-11) ...\n",
            "Setting up cm-super-minimal (0.3.4-11) ...\n",
            "Setting up cm-super (0.3.4-11) ...\n",
            "Creating fonts. This may take some time... done.\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Processing triggers for tex-common (6.09) ...\n",
            "Running mktexlsr. This may take some time... done.\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pyDOE\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/ac/91fe4c039e2744466621343d3b8af4a485193ed0aab53af5b1db03be0989/pyDOE-0.3.8.zip\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from pyDOE) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from pyDOE) (1.4.1)\n",
            "Building wheels for collected packages: pyDOE\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyDOE: filename=pyDOE-0.3.8-cp36-none-any.whl size=18178 sha256=49e5c0273387e22a2a2559b86a914c32c6088a8a73d75fbd8f4b9b359ad1553c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/c8/58/a6493bd415e8ba5735082b5e0c096d7c1f2933077a8ce34544\n",
            "Successfully built pyDOE\n",
            "Installing collected packages: pyDOE\n",
            "Successfully installed pyDOE-0.3.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgDvEO_7HnSn"
      },
      "source": [
        "# FIGURES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsfAE7ns_ORH"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "from datetime import datetime\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "\n",
        "def saveResultDir(save_path, save_hp):\n",
        "    now = datetime.now()\n",
        "    scriptName =  os.path.splitext(os.path.basename(sys.argv[0]))[0]\n",
        "    resDir = os.path.join(save_path, \"results\", f\"{now.strftime('%Y%m%d-%H%M%S')}-{scriptName}\")\n",
        "    os.mkdir(resDir)\n",
        "    print(\"Saving results to directory \", resDir)\n",
        "    savefig(os.path.join(resDir, \"graph\"))\n",
        "    with open(os.path.join(resDir, \"hp.json\"), \"w\") as f:\n",
        "        json.dump(save_hp, f)\n",
        "\n",
        "\n",
        "# MIT License\n",
        "# \n",
        "# Copyright (c) 2018 maziarraissi\n",
        "# \n",
        "# https://github.com/maziarraissi/PINNs\n",
        "\n",
        "def figsize(scale, nplots = 1):\n",
        "    fig_width_pt = 390.0                          # Get this from LaTeX using \\the\\textwidth\n",
        "    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n",
        "    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n",
        "    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n",
        "    fig_height = nplots*fig_width*golden_mean              # height in inches\n",
        "    fig_size = [fig_width,fig_height]\n",
        "    return fig_size\n",
        "\n",
        "pgf_with_latex = {                      # setup matplotlib to use latex for output\n",
        "    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n",
        "    \"text.usetex\": True,                # use LaTeX to write all text\n",
        "    \"font.family\": \"serif\",\n",
        "    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n",
        "    \"font.sans-serif\": [],\n",
        "    \"font.monospace\": [],\n",
        "    \"axes.labelsize\": 10,               # LaTeX default is 10pt font.\n",
        "    \"font.size\": 10,\n",
        "    \"legend.fontsize\": 8,               # Make the legend/label fonts a little smaller\n",
        "    \"xtick.labelsize\": 8,\n",
        "    \"ytick.labelsize\": 8,\n",
        "    \"figure.figsize\": figsize(1.0),     # default fig size of 0.9 textwidth\n",
        "    \"pgf.preamble\": [\n",
        "        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n",
        "        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n",
        "        ]\n",
        "    }\n",
        "mpl.rcParams.update(pgf_with_latex)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# I make my own newfig and savefig functions\n",
        "def newfig(width, nplots = 1):\n",
        "    fig = plt.figure(figsize=figsize(width, nplots))\n",
        "    ax = fig.add_subplot(111)\n",
        "    return fig, ax\n",
        "\n",
        "def savefig(filename, crop = True):\n",
        "    if crop == True:\n",
        "#        plt.savefig('{}.pgf'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "        plt.savefig('{}.pdf'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "        # plt.savefig('{}.eps'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "        plt.savefig('{}.png'.format(filename), bbox_inches='tight', pad_inches=0)\n",
        "    else:\n",
        "#        plt.savefig('{}.pgf'.format(filename))\n",
        "        plt.savefig('{}.pdf'.format(filename))\n",
        "        # plt.savefig('{}.eps'.format(filename))\n",
        "        plt.savefig('{}.png'.format(filename))\n",
        "\n",
        "## Simple plot\n",
        "#fig, ax  = newfig(1.0)\n",
        "#\n",
        "#def ema(y, a):\n",
        "#    s = []\n",
        "#    s.append(y[0])\n",
        "#    for t in range(1, len(y)):\n",
        "#        s.append(a * y[t] + (1-a) * s[t-1])\n",
        "#    return np.array(s)\n",
        "#    \n",
        "#y = [0]*200\n",
        "#y.extend([20]*(1000-len(y)))\n",
        "#s = ema(y, 0.01)\n",
        "#\n",
        "#ax.plot(s)\n",
        "#ax.set_xlabel('X Label')\n",
        "#ax.set_ylabel('EMA')\n",
        "#\n",
        "#savefig('ema')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55W7M8nkHgi8"
      },
      "source": [
        "# INFORMATIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njniDEGr77xp"
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "class Logger(object):\n",
        "    def __init__(self, hp):\n",
        "        print(\"Hyperparameters:\")\n",
        "        print(json.dumps(hp, indent=2))\n",
        "        print()\n",
        "\n",
        "        print(\"TensorFlow version: {}\".format(tf.__version__))\n",
        "        print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
        "        print(\"GPU-accerelated: {}\".format(tf.test.is_gpu_available()))\n",
        "\n",
        "        self.start_time = time.time()\n",
        "        self.prev_time = self.start_time\n",
        "        self.frequency = hp[\"log_frequency\"]\n",
        "\n",
        "    def get_epoch_duration(self):\n",
        "        now = time.time()\n",
        "        edur = datetime.fromtimestamp(now - self.prev_time) \\\n",
        "            .strftime(\"%S.%f\")[:-5]\n",
        "        self.prev_time = now\n",
        "        return edur\n",
        "\n",
        "    def get_elapsed(self):\n",
        "        return datetime.fromtimestamp(time.time() - self.start_time) \\\n",
        "                .strftime(\"%M:%S\")\n",
        "\n",
        "    def get_error_u(self):\n",
        "        return self.error_fn()\n",
        "\n",
        "    def set_error_fn(self, error_fn):\n",
        "        self.error_fn = error_fn\n",
        "\n",
        "    def log_train_start(self, model, model_description=False):\n",
        "        print(\"\\nTraining started\")\n",
        "        print(\"================\")\n",
        "        self.model = model\n",
        "        if model_description:\n",
        "            print(model.summary())\n",
        "\n",
        "    def log_train_epoch(self, epoch, loss, custom=\"\", is_iter=False):\n",
        "        if epoch % self.frequency == 0:\n",
        "            name = 'nt_epoch' if is_iter else 'tf_epoch'\n",
        "            print(f\"{name} = {epoch:6d}  \" +\n",
        "                  f\"elapsed = {self.get_elapsed()} \" +\n",
        "                  f\"(+{self.get_epoch_duration()})  \" +\n",
        "                  f\"loss = {loss:.4e}  \" + custom)\n",
        "\n",
        "    def log_train_opt(self, name):\n",
        "        print(f\"-- Starting {name} optimization --\")\n",
        "\n",
        "    def log_train_end(self, epoch, custom=\"\"):\n",
        "        print(\"==================\")\n",
        "        print(f\"Training finished (epoch {epoch}): \" +\n",
        "              f\"duration = {self.get_elapsed()}  \" +\n",
        "              f\"error = {self.get_error_u():.4e}  \" + custom)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CblmTR6zHOgB"
      },
      "source": [
        "Defining the costum NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI14rDnv78rH"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork(object):\n",
        "    def __init__(self, hp, logger, ub, lb):\n",
        "\n",
        "        layers = hp[\"layers\"]\n",
        "\n",
        "        # Setting up the optimizers with the hyper-parameters\n",
        "        self.nt_config = Struct()\n",
        "        self.nt_config.learningRate = hp[\"nt_lr\"]\n",
        "        self.nt_config.maxIter = hp[\"nt_epochs\"]\n",
        "        self.nt_config.nCorrection = hp[\"nt_ncorr\"]\n",
        "        self.nt_config.tolFun = 1.0 * np.finfo(float).eps\n",
        "        self.tf_epochs = hp[\"tf_epochs\"]\n",
        "        self.tf_optimizer = tf.keras.optimizers.Adam(\n",
        "            learning_rate=hp[\"tf_lr\"],\n",
        "            beta_1=hp[\"tf_b1\"],\n",
        "            epsilon=hp[\"tf_eps\"])\n",
        "\n",
        "        self.dtype = \"float64\"\n",
        "        # Descriptive Keras model\n",
        "        tf.keras.backend.set_floatx(self.dtype)\n",
        "        self.model = tf.keras.Sequential()\n",
        "        self.model.add(tf.keras.layers.InputLayer(input_shape=(layers[0],)))\n",
        "        self.model.add(tf.keras.layers.Lambda(\n",
        "            lambda X: 2.0*(X - lb)/(ub - lb) - 1.0))\n",
        "        for width in layers[1:-1]:\n",
        "            self.model.add(tf.keras.layers.Dense(\n",
        "                width, activation=tf.nn.tanh,\n",
        "                kernel_initializer=\"glorot_normal\"))\n",
        "        self.model.add(tf.keras.layers.Dense(\n",
        "                layers[-1], activation=None,\n",
        "                kernel_initializer=\"glorot_normal\"))\n",
        "\n",
        "        # Computing the sizes of weights/biases for future decomposition\n",
        "        self.sizes_w = []\n",
        "        self.sizes_b = []\n",
        "        for i, width in enumerate(layers):\n",
        "            if i != 1:\n",
        "                self.sizes_w.append(int(width * layers[1]))\n",
        "                self.sizes_b.append(int(width if i != 0 else layers[1]))\n",
        "\n",
        "        self.logger = logger\n",
        "\n",
        "    # Defining custom loss\n",
        "    # @tf.function\n",
        "    def loss(self, u, u_pred):\n",
        "        return tf.reduce_mean(tf.square(u - u_pred))\n",
        "\n",
        "    # @tf.function\n",
        "    def grad(self, X, u):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss_value = self.loss(u, self.model(X))\n",
        "        grads = tape.gradient(loss_value, self.wrap_training_variables())\n",
        "        return loss_value, grads\n",
        "\n",
        "    def wrap_training_variables(self):\n",
        "        var = self.model.trainable_variables\n",
        "        return var\n",
        "\n",
        "    def get_params(self, numpy=False):\n",
        "        return []\n",
        "\n",
        "    def get_weights(self, convert_to_tensor=True):\n",
        "        w = []\n",
        "        for layer in self.model.layers[1:]:\n",
        "            weights_biases = layer.get_weights()\n",
        "            weights = weights_biases[0].flatten()\n",
        "            biases = weights_biases[1]\n",
        "            w.extend(weights)\n",
        "            w.extend(biases)\n",
        "        if convert_to_tensor:\n",
        "            w = self.tensor(w)\n",
        "        return w\n",
        "\n",
        "    def set_weights(self, w):\n",
        "        for i, layer in enumerate(self.model.layers[1:]):\n",
        "            start_weights = sum(self.sizes_w[:i]) + sum(self.sizes_b[:i])\n",
        "            end_weights = sum(self.sizes_w[:i+1]) + sum(self.sizes_b[:i])\n",
        "            weights = w[start_weights:end_weights]\n",
        "            w_div = int(self.sizes_w[i] / self.sizes_b[i])\n",
        "            weights = tf.reshape(weights, [w_div, self.sizes_b[i]])\n",
        "            biases = w[end_weights:end_weights + self.sizes_b[i]]\n",
        "            weights_biases = [weights, biases]\n",
        "            layer.set_weights(weights_biases)\n",
        "\n",
        "    def get_loss_and_flat_grad(self, X, u):\n",
        "        def loss_and_flat_grad(w):\n",
        "            with tf.GradientTape() as tape:\n",
        "                self.set_weights(w)\n",
        "                loss_value = self.loss(u, self.model(X))\n",
        "            grad = tape.gradient(loss_value, self.wrap_training_variables())\n",
        "            grad_flat = []\n",
        "            for g in grad:\n",
        "                grad_flat.append(tf.reshape(g, [-1]))\n",
        "            grad_flat = tf.concat(grad_flat, 0)\n",
        "            return loss_value, grad_flat\n",
        "\n",
        "        return loss_and_flat_grad\n",
        "\n",
        "    def tf_optimization(self, X_u, u):\n",
        "        self.logger.log_train_opt(\"Adam\")\n",
        "        for epoch in range(self.tf_epochs):\n",
        "            loss_value = self.tf_optimization_step(X_u, u)\n",
        "            self.logger.log_train_epoch(epoch, loss_value)\n",
        "\n",
        "    # @tf.function\n",
        "    def tf_optimization_step(self, X_u, u):\n",
        "        loss_value, grads = self.grad(X_u, u)\n",
        "        self.tf_optimizer.apply_gradients(\n",
        "                zip(grads, self.wrap_training_variables()))\n",
        "        return loss_value\n",
        "\n",
        "    def nt_optimization(self, X_u, u):\n",
        "        self.logger.log_train_opt(\"LBFGS\")\n",
        "        loss_and_flat_grad = self.get_loss_and_flat_grad(X_u, u)\n",
        "        # tfp.optimizer.lbfgs_minimize(\n",
        "        #   loss_and_flat_grad,\n",
        "        #   initial_position=self.get_weights(),\n",
        "        #   num_correction_pairs=nt_config.nCorrection,\n",
        "        #   max_iterations=nt_config.maxIter,\n",
        "        #   f_relative_tolerance=nt_config.tolFun,\n",
        "        #   tolerance=nt_config.tolFun,\n",
        "        #   parallel_iterations=6)\n",
        "        self.nt_optimization_steps(loss_and_flat_grad)\n",
        "\n",
        "    def nt_optimization_steps(self, loss_and_flat_grad):\n",
        "        lbfgs(loss_and_flat_grad,\n",
        "              self.get_weights(),\n",
        "              self.nt_config, Struct(), True,\n",
        "              lambda epoch, loss, is_iter:\n",
        "              self.logger.log_train_epoch(epoch, loss, \"\", is_iter))\n",
        "\n",
        "    def fit(self, X_u, u):\n",
        "        self.logger.log_train_start(self)\n",
        "\n",
        "        # Creating the tensors\n",
        "        X_u = self.tensor(X_u)\n",
        "        u = self.tensor(u)\n",
        "\n",
        "        # Optimizing\n",
        "        self.tf_optimization(X_u, u)\n",
        "        self.nt_optimization(X_u, u)\n",
        "\n",
        "        self.logger.log_train_end(self.tf_epochs + self.nt_config.maxIter)\n",
        "\n",
        "    def predict(self, X_star):\n",
        "        u_pred = self.model(X_star)\n",
        "        return u_pred.numpy()\n",
        "\n",
        "    def summary(self):\n",
        "        return self.model.summary()\n",
        "\n",
        "    def tensor(self, X):\n",
        "        return tf.convert_to_tensor(X, dtype=self.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FX1xijuHI4W"
      },
      "source": [
        "## Defining **lbfgs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PRe016z_GqJ"
      },
      "source": [
        "#%% Adapted from https://github.com/yaroslavvb/stuff/blob/master/eager_lbfgs/eager_lbfgs.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Time tracking functions\n",
        "global_time_list = []\n",
        "global_last_time = 0\n",
        "def reset_time():\n",
        "  global global_time_list, global_last_time\n",
        "  global_time_list = []\n",
        "  global_last_time = time.perf_counter()\n",
        "  \n",
        "def record_time():\n",
        "  global global_last_time, global_time_list\n",
        "  new_time = time.perf_counter()\n",
        "  global_time_list.append(new_time - global_last_time)\n",
        "  global_last_time = time.perf_counter()\n",
        "  #print(\"step: %.2f\"%(global_time_list[-1]*1000))\n",
        "\n",
        "def last_time():\n",
        "  \"\"\"Returns last interval records in millis.\"\"\"\n",
        "  global global_last_time, global_time_list\n",
        "  if global_time_list:\n",
        "    return 1000 * global_time_list[-1]\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def dot(a, b):\n",
        "  \"\"\"Dot product function since TensorFlow doesn't have one.\"\"\"\n",
        "  return tf.reduce_sum(a*b)\n",
        "\n",
        "def verbose_func(s):\n",
        "  print(s)\n",
        "\n",
        "final_loss = None\n",
        "times = []\n",
        "def lbfgs(opfunc, x, config, state, do_verbose, log_fn):\n",
        "  \"\"\"port of lbfgs.lua, using TensorFlow eager mode.\n",
        "  \"\"\"\n",
        "\n",
        "  if config.maxIter == 0:\n",
        "    return\n",
        "\n",
        "  global final_loss, times\n",
        "  \n",
        "  maxIter = config.maxIter\n",
        "  maxEval = config.maxEval or maxIter*1.25\n",
        "  tolFun = config.tolFun or 1e-5\n",
        "  tolX = config.tolX or 1e-19\n",
        "  nCorrection = config.nCorrection or 100\n",
        "  lineSearch = config.lineSearch\n",
        "  lineSearchOpts = config.lineSearchOptions\n",
        "  learningRate = config.learningRate or 1\n",
        "  isverbose = config.verbose or False\n",
        "\n",
        "  # verbose function\n",
        "  if isverbose:\n",
        "    verbose = verbose_func\n",
        "  else:\n",
        "    verbose = lambda x: None\n",
        "\n",
        "    # evaluate initial f(x) and df/dx\n",
        "  f, g = opfunc(x)\n",
        "\n",
        "  f_hist = [f]\n",
        "  currentFuncEval = 1\n",
        "  state.funcEval = state.funcEval + 1\n",
        "  p = g.shape[0]\n",
        "\n",
        "  # check optimality of initial point\n",
        "  tmp1 = tf.abs(g)\n",
        "  if tf.reduce_sum(tmp1) <= tolFun:\n",
        "    verbose(\"optimality condition below tolFun\")\n",
        "    return x, f_hist\n",
        "\n",
        "  # optimize for a max of maxIter iterations\n",
        "  nIter = 0\n",
        "  times = []\n",
        "  while nIter < maxIter:\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # keep track of nb of iterations\n",
        "    nIter = nIter + 1\n",
        "    state.nIter = state.nIter + 1\n",
        "\n",
        "    ############################################################\n",
        "    ## compute gradient descent direction\n",
        "    ############################################################\n",
        "    if state.nIter == 1:\n",
        "      d = -g\n",
        "      old_dirs = []\n",
        "      old_stps = []\n",
        "      Hdiag = 1\n",
        "    else:\n",
        "      # do lbfgs update (update memory)\n",
        "      y = g - g_old\n",
        "      s = d*t\n",
        "      ys = dot(y, s)\n",
        "      \n",
        "      if ys > 1e-10:\n",
        "        # updating memory\n",
        "        if len(old_dirs) == nCorrection:\n",
        "          # shift history by one (limited-memory)\n",
        "          del old_dirs[0]\n",
        "          del old_stps[0]\n",
        "\n",
        "        # store new direction/step\n",
        "        old_dirs.append(s)\n",
        "        old_stps.append(y)\n",
        "\n",
        "        # update scale of initial Hessian approximation\n",
        "        Hdiag = ys/dot(y, y)\n",
        "\n",
        "      # compute the approximate (L-BFGS) inverse Hessian \n",
        "      # multiplied by the gradient\n",
        "      k = len(old_dirs)\n",
        "\n",
        "      # need to be accessed element-by-element, so don't re-type tensor:\n",
        "      ro = [0]*nCorrection\n",
        "      for i in range(k):\n",
        "        ro[i] = 1/dot(old_stps[i], old_dirs[i])\n",
        "        \n",
        "\n",
        "      # iteration in L-BFGS loop collapsed to use just one buffer\n",
        "      # need to be accessed element-by-element, so don't re-type tensor:\n",
        "      al = [0]*nCorrection\n",
        "\n",
        "      q = -g\n",
        "      for i in range(k-1, -1, -1):\n",
        "        al[i] = dot(old_dirs[i], q) * ro[i]\n",
        "        q = q - al[i]*old_stps[i]\n",
        "\n",
        "      # multiply by initial Hessian\n",
        "      r = q*Hdiag\n",
        "      for i in range(k):\n",
        "        be_i = dot(old_stps[i], r) * ro[i]\n",
        "        r += (al[i]-be_i)*old_dirs[i]\n",
        "        \n",
        "      d = r\n",
        "      # final direction is in r/d (same object)\n",
        "\n",
        "    g_old = g\n",
        "    f_old = f\n",
        "    \n",
        "    ############################################################\n",
        "    ## compute step length\n",
        "    ############################################################\n",
        "    # directional derivative\n",
        "    gtd = dot(g, d)\n",
        "\n",
        "    # check that progress can be made along that direction\n",
        "    if gtd > -tolX:\n",
        "      verbose(\"Can not make progress along direction.\")\n",
        "      break\n",
        "\n",
        "    # reset initial guess for step size\n",
        "    if state.nIter == 1:\n",
        "      tmp1 = tf.abs(g)\n",
        "      t = min(1, 1/tf.reduce_sum(tmp1))\n",
        "    else:\n",
        "      t = learningRate\n",
        "\n",
        "\n",
        "    # optional line search: user function\n",
        "    lsFuncEval = 0\n",
        "    if lineSearch and isinstance(lineSearch) == types.FunctionType:\n",
        "      # perform line search, using user function\n",
        "      f,g,x,t,lsFuncEval = lineSearch(opfunc,x,t,d,f,g,gtd,lineSearchOpts)\n",
        "      f_hist.append(f)\n",
        "    else:\n",
        "      # no line search, simply move with fixed-step\n",
        "      x += t*d\n",
        "      \n",
        "      if nIter != maxIter:\n",
        "        # re-evaluate function only if not in last iteration\n",
        "        # the reason we do this: in a stochastic setting,\n",
        "        # no use to re-evaluate that function here\n",
        "        f, g = opfunc(x)\n",
        "        lsFuncEval = 1\n",
        "        f_hist.append(f)\n",
        "\n",
        "\n",
        "    # update func eval\n",
        "    currentFuncEval = currentFuncEval + lsFuncEval\n",
        "    state.funcEval = state.funcEval + lsFuncEval\n",
        "\n",
        "    ############################################################\n",
        "    ## check conditions\n",
        "    ############################################################\n",
        "    if nIter == maxIter:\n",
        "      break\n",
        "\n",
        "    if currentFuncEval >= maxEval:\n",
        "      # max nb of function evals\n",
        "      verbose('max nb of function evals')\n",
        "      break\n",
        "\n",
        "    tmp1 = tf.abs(g)\n",
        "    if tf.reduce_sum(tmp1) <=tolFun:\n",
        "      # check optimality\n",
        "      verbose('optimality condition below tolFun')\n",
        "      break\n",
        "    \n",
        "    tmp1 = tf.abs(d*t)\n",
        "    if tf.reduce_sum(tmp1) <= tolX:\n",
        "      # step size below tolX\n",
        "      verbose('step size below tolX')\n",
        "      break\n",
        "\n",
        "    if tf.abs(f-f_old) < tolX:\n",
        "      # function value changing less than tolX\n",
        "      verbose('function value changing less than tolX'+str(tf.abs(f-f_old)))\n",
        "      break\n",
        "\n",
        "    if do_verbose:\n",
        "      log_fn(nIter, f.numpy(), True)\n",
        "      #print(\"Step %3d loss %6.5f msec %6.3f\"%(nIter, f.numpy(), last_time()))\n",
        "      record_time()\n",
        "      times.append(last_time())\n",
        "\n",
        "    if nIter == maxIter - 1:\n",
        "      final_loss = f.numpy()\n",
        "\n",
        "\n",
        "  # save state\n",
        "  state.old_dirs = old_dirs\n",
        "  state.old_stps = old_stps\n",
        "  state.Hdiag = Hdiag\n",
        "  state.g_old = g_old\n",
        "  state.f_old = f_old\n",
        "  state.t = t\n",
        "  state.d = d\n",
        "\n",
        "  return x, f_hist, currentFuncEval\n",
        "\n",
        "# dummy/Struct gives Lua-like struct object with 0 defaults\n",
        "class dummy(object):\n",
        "  pass\n",
        "\n",
        "class Struct(dummy):\n",
        "  def __getattribute__(self, key):\n",
        "    if key == '__dict__':\n",
        "      return super(dummy, self).__getattribute__('__dict__')\n",
        "    return self.__dict__.get(key, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ET5AgMQGkyR"
      },
      "source": [
        "# Utilities:\n",
        "\n",
        "\n",
        "1.   Prepare data function\n",
        "2.   Plotting function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yYBxFmN8g58"
      },
      "source": [
        "#%% Utils for Burger's equation\n",
        "\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pyDOE import lhs\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "from scipy.interpolate import griddata\n",
        "import matplotlib.gridspec as gridspec\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "# \".\" for Colab/VSCode, and \"..\" for GitHub\n",
        "repoPath = os.path.join(\".\", \"PINNs\")\n",
        "# repoPath = os.path.join(\"..\", \"PINNs\")\n",
        "utilsPath = os.path.join(repoPath, \"Utilities\")\n",
        "dataPath = os.path.join(repoPath, \"main\", \"Data\")\n",
        "appDataPath = os.path.join(repoPath, \"appendix\", \"Data\")\n",
        "\n",
        "def prep_data(path, N_u=None, N_f=None, N_n=None, q=None, ub=None, lb=None, noise=0.0, idx_t_0=None, idx_t_1=None, N_0=None, N_1=None):\n",
        "    # Reading external data [t is 100x1, usol is 256x100 (solution), x is 256x1]\n",
        "    data = scipy.io.loadmat(path)\n",
        "\n",
        "    # Flatten makes [[]] into [], [:,None] makes it a column vector\n",
        "    t = data['t'].flatten()[:,None] # T x 1\n",
        "    x = data['x'].flatten()[:,None] # N x 1\n",
        "\n",
        "    # Keeping the 2D data for the solution data (real() is maybe to make it float by default, in case of zeroes)\n",
        "    Exact_u = np.real(data['usol']).T # T x N\n",
        "\n",
        "    # x = np.load(\"1d-burgers/data/burgers_x.npy\")[:, None]\n",
        "    # t = np.load(\"1d-burgers/data/burgers_t.npy\")[:, None]\n",
        "    # Exact_u = np.load(\"1d-burgers/data/burgers_u.npy\").T\n",
        "\n",
        "    if N_n != None and q != None and ub != None and lb != None and idx_t_0 != None and idx_t_1 != None:\n",
        "      dt = t[idx_t_1] - t[idx_t_0]\n",
        "      idx_x = np.random.choice(Exact_u.shape[1], N_n, replace=False) \n",
        "      x_0 = x[idx_x,:]\n",
        "      u_0 = Exact_u[idx_t_0:idx_t_0+1,idx_x].T\n",
        "      u_0 = u_0 + noise*np.std(u_0)*np.random.randn(u_0.shape[0], u_0.shape[1])\n",
        "        \n",
        "      # Boudanry data\n",
        "      x_1 = np.vstack((lb, ub))\n",
        "      \n",
        "      # Test data\n",
        "      x_star = x\n",
        "      u_star = Exact_u[idx_t_1,:]\n",
        "\n",
        "      # Load IRK weights\n",
        "      tmp = np.float32(np.loadtxt(os.path.join(utilsPath, \"IRK_weights\", \"Butcher_IRK%d.txt\" % (q)), ndmin = 2))\n",
        "      IRK_weights = np.reshape(tmp[0:q**2+q], (q+1,q))\n",
        "      IRK_times = tmp[q**2+q:]\n",
        "\n",
        "      return x, t, dt, Exact_u, x_0, u_0, x_1, x_star, u_star, IRK_weights, IRK_times\n",
        "\n",
        "    # Meshing x and t in 2D (256,100)\n",
        "    X, T = np.meshgrid(x,t)\n",
        "\n",
        "    # Preparing the inputs x and t (meshed as X, T) for predictions in one single array, as X_star\n",
        "    X_star = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
        "\n",
        "    # Preparing the testing u_star\n",
        "    u_star = Exact_u.flatten()[:,None]\n",
        "                \n",
        "    # Noiseless data TODO: add support for noisy data    \n",
        "    idx = np.random.choice(X_star.shape[0], N_u, replace=False)\n",
        "    X_u_train = X_star[idx,:]\n",
        "    u_train = u_star[idx,:]\n",
        "\n",
        "    if N_0 != None and N_1 != None:\n",
        "      Exact_u = Exact_u.T\n",
        "      idx_x = np.random.choice(Exact_u.shape[0], N_0, replace=False)\n",
        "      x_0 = x[idx_x,:]\n",
        "      u_0 = Exact_u[idx_x,idx_t_0][:,None]\n",
        "      u_0 = u_0 + noise*np.std(u_0)*np.random.randn(u_0.shape[0], u_0.shape[1])\n",
        "          \n",
        "      idx_x = np.random.choice(Exact_u.shape[0], N_1, replace=False)\n",
        "      x_1 = x[idx_x,:]\n",
        "      u_1 = Exact_u[idx_x,idx_t_1][:,None]\n",
        "      u_1 = u_1 + noise*np.std(u_1)*np.random.randn(u_1.shape[0], u_1.shape[1])\n",
        "      \n",
        "      dt = np.asscalar(t[idx_t_1] - t[idx_t_0])        \n",
        "      q = int(np.ceil(0.5*np.log(np.finfo(float).eps)/np.log(dt)))\n",
        "\n",
        "      # Load IRK weights\n",
        "      tmp = np.float32(np.loadtxt(os.path.join(utilsPath, \"IRK_weights\", \"Butcher_IRK%d.txt\" % (q)), ndmin = 2))\n",
        "      weights =  np.reshape(tmp[0:q**2+q], (q+1,q))     \n",
        "      IRK_alpha = weights[0:-1,:]\n",
        "      IRK_beta = weights[-1:,:] \n",
        "      return x_0, u_0, x_1, u_1, x, t, dt, q, Exact_u, IRK_alpha, IRK_beta\n",
        "\n",
        "    if N_f == None:\n",
        "      lb = X_star.min(axis=0)\n",
        "      ub = X_star.max(axis=0) \n",
        "      return x, t, X, T, Exact_u, X_star, u_star, X_u_train, u_train, ub, lb\n",
        "\n",
        "    # Domain bounds (lowerbounds upperbounds) [x, t], which are here ([-1.0, 0.0] and [1.0, 1.0])\n",
        "    lb = X_star.min(axis=0)\n",
        "    ub = X_star.max(axis=0) \n",
        "    # Getting the initial conditions (t=0)\n",
        "    xx1 = np.hstack((X[0:1,:].T, T[0:1,:].T))\n",
        "    uu1 = Exact_u[0:1,:].T\n",
        "    # Getting the lowest boundary conditions (x=-1) \n",
        "    xx2 = np.hstack((X[:,0:1], T[:,0:1]))\n",
        "    uu2 = Exact_u[:,0:1]\n",
        "    # Getting the highest boundary conditions (x=1) \n",
        "    xx3 = np.hstack((X[:,-1:], T[:,-1:]))\n",
        "    uu3 = Exact_u[:,-1:]\n",
        "    # Stacking them in multidimensional tensors for training (X_u_train is for now the continuous boundaries)\n",
        "    X_u_train = np.vstack([xx1, xx2, xx3])\n",
        "    u_train = np.vstack([uu1, uu2, uu3])\n",
        "\n",
        "    # Generating the x and t collocation points for f, with each having a N_f size\n",
        "    # We pointwise add and multiply to spread the LHS over the 2D domain\n",
        "    X_f_train = lb + (ub-lb)*lhs(2, N_f)\n",
        "\n",
        "    # Generating a uniform random sample from ints between 0, and the size of x_u_train, of size N_u (initial data size) and without replacement (unique)\n",
        "    idx = np.random.choice(X_u_train.shape[0], N_u, replace=False)\n",
        "    # Getting the corresponding X_u_train (which is now scarce boundary/initial coordinates)\n",
        "    X_u_train = X_u_train[idx,:]\n",
        "    # Getting the corresponding u_train\n",
        "    u_train = u_train [idx,:]\n",
        "\n",
        "    return x, t, X, T, Exact_u, X_star, u_star, X_u_train, u_train, X_f_train, ub, lb\n",
        "\n",
        "def plot_inf_cont_results(X_star, u_pred, X_u_train, u_train, Exact_u, X, T, x, t, save_path=None, save_hp=None):\n",
        "\n",
        "  # Interpolating the results on the whole (x,t) domain.\n",
        "  # griddata(points, values, points at which to interpolate, method)\n",
        "  U_pred = griddata(X_star, u_pred, (X, T), method='cubic')\n",
        "\n",
        "  # Creating the figures\n",
        "  fig, ax = newfig(1.0, 1.1)\n",
        "  ax.axis('off')\n",
        "\n",
        "  ####### Row 0: u(t,x) ##################    \n",
        "  gs0 = gridspec.GridSpec(1, 2)\n",
        "  gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
        "  ax = plt.subplot(gs0[:, :])\n",
        "\n",
        "  h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "                extent=[t.min(), t.max(), x.min(), x.max()], \n",
        "                origin='lower', aspect='auto')\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  fig.colorbar(h, cax=cax)\n",
        "\n",
        "  ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 4, clip_on = False)\n",
        "\n",
        "  line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "  ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)    \n",
        "\n",
        "  ax.set_xlabel('$t$')\n",
        "  ax.set_ylabel('$x$')\n",
        "  ax.legend(frameon=False, loc = 'best')\n",
        "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "\n",
        "  ####### Row 1: u(t,x) slices ##################    \n",
        "  gs1 = gridspec.GridSpec(1, 3)\n",
        "  gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5)\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 0])\n",
        "  ax.plot(x,Exact_u[25,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "  ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')    \n",
        "  ax.set_title('$t = 0.25$', fontsize = 10)\n",
        "  ax.axis('square')\n",
        "  ax.set_xlim([-1.1,1.1])\n",
        "  ax.set_ylim([-1.1,1.1])\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 1])\n",
        "  ax.plot(x,Exact_u[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "  ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.axis('square')\n",
        "  ax.set_xlim([-1.1,1.1])\n",
        "  ax.set_ylim([-1.1,1.1])\n",
        "  ax.set_title('$t = 0.50$', fontsize = 10)\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 2])\n",
        "  ax.plot(x,Exact_u[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "  ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.axis('square')\n",
        "  ax.set_xlim([-1.1,1.1])\n",
        "  ax.set_ylim([-1.1,1.1])    \n",
        "  ax.set_title('$t = 0.75$', fontsize = 10)\n",
        "\n",
        "  if save_path != None and save_hp != None:\n",
        "      saveResultDir(save_path, save_hp)\n",
        "\n",
        "  else:\n",
        "    plt.show()\n",
        "\n",
        "def plot_inf_disc_results(x_star, idx_t_0, idx_t_1, x_0, u_0, ub, lb, u_1_pred, Exact_u, x, t, save_path=None, save_hp=None):\n",
        "  fig, ax = newfig(1.0, 1.2)\n",
        "  ax.axis('off')\n",
        "  \n",
        "  ####### Row 0: h(t,x) ##################    \n",
        "  gs0 = gridspec.GridSpec(1, 2)\n",
        "  gs0.update(top=1-0.06, bottom=1-1/2 + 0.1, left=0.15, right=0.85, wspace=0)\n",
        "  ax = plt.subplot(gs0[:, :])\n",
        "  \n",
        "  h = ax.imshow(Exact_u.T, interpolation='nearest', cmap='rainbow', \n",
        "                extent=[t.min(), t.max(), x_star.min(), x_star.max()], \n",
        "                origin='lower', aspect='auto')\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  fig.colorbar(h, cax=cax)\n",
        "      \n",
        "  line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "  ax.plot(t[idx_t_0]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  ax.plot(t[idx_t_1]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "  \n",
        "  ax.set_xlabel('$t$')\n",
        "  ax.set_ylabel('$x$')\n",
        "  leg = ax.legend(frameon=False, loc = 'best')\n",
        "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "  \n",
        "  \n",
        "  ####### Row 1: h(t,x) slices ##################    \n",
        "  gs1 = gridspec.GridSpec(1, 2)\n",
        "  gs1.update(top=1-1/2-0.05, bottom=0.15, left=0.15, right=0.85, wspace=0.5)\n",
        "  \n",
        "  ax = plt.subplot(gs1[0, 0])\n",
        "  ax.plot(x,Exact_u[idx_t_0,:], 'b-', linewidth = 2) \n",
        "  ax.plot(x_0, u_0, 'rx', linewidth = 2, label = 'Data')      \n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')    \n",
        "  ax.set_title('$t = %.2f$' % (t[idx_t_0]), fontsize = 10)\n",
        "  ax.set_xlim([lb-0.1, ub+0.1])\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.8, -0.3), ncol=2, frameon=False)\n",
        "\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 1])\n",
        "  ax.plot(x, Exact_u[idx_t_1,:], 'b-', linewidth = 2, label = 'Exact') \n",
        "  ax.plot(x_star, u_1_pred, 'r--', linewidth = 2, label = 'Prediction')      \n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')    \n",
        "  ax.set_title('$t = %.2f$' % (t[idx_t_1]), fontsize = 10)    \n",
        "  ax.set_xlim([lb-0.1, ub+0.1])\n",
        "  \n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(0.1, -0.3), ncol=2, frameon=False)\n",
        "\n",
        "  if save_path != None and save_hp != None:\n",
        "      saveResultDir(save_path, save_hp)\n",
        "\n",
        "  else:\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_ide_disc_results(x_star, t_star, idx_t_0, idx_t_1, x_0, u_0, x_1, u_1,\n",
        "  ub, lb, u_1_pred, Exact, lambda_1_value, lambda_1_value_noisy, lambda_2_value, lambda_2_value_noisy,\n",
        "  x, t, save_path=None, save_hp=None):  \n",
        "  fig, ax = newfig(1.0, 1.5)\n",
        "  ax.axis('off')\n",
        "  \n",
        "  gs0 = gridspec.GridSpec(1, 2)\n",
        "  gs0.update(top=1-0.06, bottom=1-1/3+0.05, left=0.15, right=0.85, wspace=0)\n",
        "  ax = plt.subplot(gs0[:, :])\n",
        "      \n",
        "  h = ax.imshow(Exact, interpolation='nearest', cmap='rainbow',\n",
        "                extent=[t_star.min(),t_star.max(), lb[0], ub[0]],\n",
        "                origin='lower', aspect='auto')\n",
        "  divider = make_axes_locatable(ax)\n",
        "  cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "  fig.colorbar(h, cax=cax)\n",
        "  \n",
        "  line = np.linspace(x_star.min(), x_star.max(), 2)[:,None]\n",
        "  ax.plot(t_star[idx_t_0]*np.ones((2,1)), line, 'w-', linewidth = 1.0)\n",
        "  ax.plot(t_star[idx_t_1]*np.ones((2,1)), line, 'w-', linewidth = 1.0)    \n",
        "  ax.set_xlabel('$t$')\n",
        "  ax.set_ylabel('$x$')\n",
        "  ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "  \n",
        "  gs1 = gridspec.GridSpec(1, 2)\n",
        "  gs1.update(top=1-1/3-0.1, bottom=1-2/3, left=0.15, right=0.85, wspace=0.5)\n",
        "\n",
        "  ax = plt.subplot(gs1[0, 0])\n",
        "  ax.plot(x_star,Exact[:,idx_t_0][:,None], 'b', linewidth = 2, label = 'Exact')\n",
        "  ax.plot(x_0, u_0, 'rx', linewidth = 2, label = 'Data')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.set_title('$t = %.2f$\\n%d trainng data' % (t_star[idx_t_0], u_0.shape[0]), fontsize = 10)\n",
        "  \n",
        "  ax = plt.subplot(gs1[0, 1])\n",
        "  ax.plot(x_star,Exact[:,idx_t_1][:,None], 'b', linewidth = 2, label = 'Exact')\n",
        "  ax.plot(x_1, u_1, 'rx', linewidth = 2, label = 'Data')\n",
        "  ax.set_xlabel('$x$')\n",
        "  ax.set_ylabel('$u(t,x)$')\n",
        "  ax.set_title('$t = %.2f$\\n%d trainng data' % (t_star[idx_t_1], u_1.shape[0]), fontsize = 10)\n",
        "  ax.legend(loc='upper center', bbox_to_anchor=(-0.3, -0.3), ncol=2, frameon=False)\n",
        "  \n",
        "  gs2 = gridspec.GridSpec(1, 2)\n",
        "  gs2.update(top=1-2/3-0.05, bottom=0, left=0.15, right=0.85, wspace=0.0)\n",
        "  \n",
        "  ax = plt.subplot(gs2[0, 0])\n",
        "  ax.axis('off')\n",
        "  nu = 0.01/np.pi\n",
        "  s1 = r'$\\begin{tabular}{ |c|c| }  \\hline Correct PDE & $u_t + u u_x + %.6f u_{xx} = 0$ \\\\  \\hline Identified PDE (clean data) & ' % (nu)\n",
        "  s2 = r'$u_t + %.3f u u_x + %.6f u_{xx} = 0$ \\\\  \\hline ' % (lambda_1_value, lambda_2_value)\n",
        "  s3 = r'Identified PDE (1\\% noise) & '\n",
        "  s4 = r'$u_t + %.3f u u_x + %.6f u_{xx} = 0$  \\\\  \\hline ' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "  s5 = r'\\end{tabular}$'\n",
        "  s = s1+s2+s3+s4+s5\n",
        "  ax.text(-0.1,0.2,s)\n",
        "\n",
        "  if save_path != None and save_hp != None:\n",
        "      saveResultDir(save_path, save_hp)\n",
        "\n",
        "  else:\n",
        "    plt.show()\n",
        "\n",
        "def plot_ide_cont_results(X_star, u_pred, X_u_train, u_train,\n",
        "  Exact_u, X, T, x, t, lambda_1_value, lambda_1_value_noisy, lambda_2_value, lambda_2_value_noisy):\n",
        "    fig, ax = newfig(1.0, 1.4)\n",
        "    ax.axis('off')\n",
        "\n",
        "    U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')\n",
        "    \n",
        "    ####### Row 0: u(t,x) ##################    \n",
        "    gs0 = gridspec.GridSpec(1, 2)\n",
        "    gs0.update(top=1-0.06, bottom=1-1.0/3.0+0.06, left=0.15, right=0.85, wspace=0)\n",
        "    ax = plt.subplot(gs0[:, :])\n",
        "    \n",
        "    h = ax.imshow(U_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "                  extent=[t.min(), t.max(), x.min(), x.max()], \n",
        "                  origin='lower', aspect='auto')\n",
        "    divider = make_axes_locatable(ax)\n",
        "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
        "    fig.colorbar(h, cax=cax)\n",
        "    \n",
        "    ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label = 'Data (%d points)' % (u_train.shape[0]), markersize = 2, clip_on = False)\n",
        "    \n",
        "    line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "    ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "    \n",
        "    ax.set_xlabel('$t$')\n",
        "    ax.set_ylabel('$x$')\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(1.0, -0.125), ncol=5, frameon=False)\n",
        "    ax.set_title('$u(t,x)$', fontsize = 10)\n",
        "    \n",
        "    ####### Row 1: u(t,x) slices ##################    \n",
        "    gs1 = gridspec.GridSpec(1, 3)\n",
        "    gs1.update(top=1-1.0/3.0-0.1, bottom=1.0-2.0/3.0, left=0.1, right=0.9, wspace=0.5)\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 0])\n",
        "    ax.plot(x,Exact_u[25,:], 'b-', linewidth = 2, label = 'Exact')\n",
        "    ax.plot(x,U_pred[25,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')    \n",
        "    ax.set_title('$t = 0.25$', fontsize = 10)\n",
        "    ax.axis('square')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 1])\n",
        "    ax.plot(x,Exact_u[50,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "    ax.plot(x,U_pred[50,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')\n",
        "    ax.axis('square')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])\n",
        "    ax.set_title('$t = 0.50$', fontsize = 10)\n",
        "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
        "    \n",
        "    ax = plt.subplot(gs1[0, 2])\n",
        "    ax.plot(x,Exact_u[75,:], 'b-', linewidth = 2, label = 'Exact')       \n",
        "    ax.plot(x,U_pred[75,:], 'r--', linewidth = 2, label = 'Prediction')\n",
        "    ax.set_xlabel('$x$')\n",
        "    ax.set_ylabel('$u(t,x)$')\n",
        "    ax.axis('square')\n",
        "    ax.set_xlim([-1.1,1.1])\n",
        "    ax.set_ylim([-1.1,1.1])    \n",
        "    ax.set_title('$t = 0.75$', fontsize = 10)\n",
        "    \n",
        "    ####### Row 3: Identified PDE ##################    \n",
        "    gs2 = gridspec.GridSpec(1, 3)\n",
        "    gs2.update(top=1.0-2.0/3.0, bottom=0, left=0.0, right=1.0, wspace=0.0)\n",
        "    \n",
        "    ax = plt.subplot(gs2[:, :])\n",
        "    ax.axis('off')\n",
        "    s1 = r'$\\begin{tabular}{ |c|c| }  \\hline Correct PDE & $u_t + u u_x - 0.0031831 u_{xx} = 0$ \\\\  \\hline Identified PDE (clean data) & '\n",
        "    s2 = r'$u_t + %.5f u u_x - %.7f u_{xx} = 0$ \\\\  \\hline ' % (lambda_1_value, lambda_2_value)\n",
        "    s3 = r'Identified PDE (1\\% noise) & '\n",
        "    s4 = r'$u_t + %.5f u u_x - %.7f u_{xx} = 0$  \\\\  \\hline ' % (lambda_1_value_noisy, lambda_2_value_noisy)\n",
        "    s5 = r'\\end{tabular}$'\n",
        "    s = s1+s2+s3+s4+s5\n",
        "    ax.text(0.1,0.1,s)\n",
        "    plt.show()\n",
        "    savefig('./content/Burgers_identification')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2CZd9yt_rot"
      },
      "source": [
        "# RUnning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5uz8YCt1hn2O",
        "outputId": "1f2732a3-5767-4570-8f9e-6cbb3c3bb2df"
      },
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "# Manually making sure the numpy random seeds are \"the same\" on all devices\n",
        "np.random.seed(1234)\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "# HYPER PARAMETERS\n",
        "\n",
        "hp = {}\n",
        "# Data size on the solution u\n",
        "hp[\"N_u\"] = 2000\n",
        "# DeepNN topology (2-sized input [x t], 8 hidden layer of 20-width, 1-sized output [u]\n",
        "hp[\"layers\"] = [2, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n",
        "# Setting up the TF SGD-based optimizer (set tf_epochs=0 to cancel it)\n",
        "hp[\"tf_epochs\"] = 200\n",
        "hp[\"tf_lr\"] = 0.01\n",
        "hp[\"tf_b1\"] = 0.9\n",
        "hp[\"tf_eps\"] = None\n",
        "# Setting up the quasi-newton LBGFS optimizer (set nt_epochs=0 to cancel it)\n",
        "hp[\"nt_epochs\"] = 2000\n",
        "hp[\"nt_lr\"] = 0.8\n",
        "hp[\"nt_ncorr\"] = 50\n",
        "hp[\"log_frequency\"] = 10\n",
        "\n",
        "#%% DEFINING THE MODEL\n",
        "\n",
        "class BurgersInformedNN(NeuralNetwork):\n",
        "    def __init__(self, hp, logger, ub, lb):\n",
        "        super().__init__(hp, logger, ub, lb)\n",
        "\n",
        "        # Defining the two additional trainable variables for identification\n",
        "        self.lambda_1 = tf.Variable([0.0], dtype=self.dtype)\n",
        "        self.lambda_2 = tf.Variable([-6.0], dtype=self.dtype)\n",
        "\n",
        "  # The actual PINN\n",
        "    def f_model(self, X_u):\n",
        "      l1, l2 = self.get_params()\n",
        "    # Separating the collocation coordinates\n",
        "      x_f = tf.convert_to_tensor(X_u[:, 0:1], dtype=self.dtype)\n",
        "      t_f = tf.convert_to_tensor(X_u[:, 1:2], dtype=self.dtype)\n",
        "\n",
        "      # Using the new GradientTape paradigm of TF2.0,\n",
        "      # which keeps track of operations to get the gradient at runtime\n",
        "      with tf.GradientTape(persistent=True) as tape:\n",
        "        # Watching the two inputs we’ll need later, x and t\n",
        "        tape.watch(x_f)\n",
        "        tape.watch(t_f)\n",
        "        # Packing together the inputs\n",
        "        X_f = tf.stack([x_f[:,0], t_f[:,0]], axis=1)\n",
        "\n",
        "\n",
        "        # Getting the prediction\n",
        "        u = self.model(X_f)\n",
        "        # Deriving INSIDE the tape (since we’ll need the x derivative of this later, u_xx)\n",
        "        u_x = tape.gradient(u, x_f)\n",
        "\n",
        "      # Getting the other derivatives\n",
        "      u_xx = tape.gradient(u_x, x_f)\n",
        "      u_t = tape.gradient(u, t_f)\n",
        "\n",
        "      # Letting the tape go\n",
        "      del tape\n",
        "\n",
        "      # Buidling the PINNs\n",
        "      return u_t + l1*u*u_x - l2*u_xx\n",
        "\n",
        "  # Defining custom loss\n",
        "    def loss(self, u, u_pred):\n",
        "        f_pred = self.f_model(self.X_u)\n",
        "        return tf.reduce_mean(tf.square(u - u_pred)) + \\\n",
        "              tf.reduce_mean(tf.square(f_pred))\n",
        "\n",
        "    def wrap_training_variables(self):\n",
        "      var = self.model.trainable_variables\n",
        "      var.extend([self.lambda_1, self.lambda_2])\n",
        "      return var\n",
        "\n",
        "    def get_weights(self):\n",
        "        w = super().get_weights(convert_to_tensor=False)\n",
        "        w.extend(self.lambda_1.numpy())\n",
        "        w.extend(self.lambda_2.numpy())\n",
        "        return tf.convert_to_tensor(w, dtype=self.dtype)\n",
        "\n",
        "    def set_weights(self, w):\n",
        "      super().set_weights(w)\n",
        "      self.lambda_1.assign([w[-2]])\n",
        "      self.lambda_2.assign([w[-1]])\n",
        "\n",
        "    def get_params(self, numpy=False):\n",
        "      l1 = self.lambda_1\n",
        "      l2 = tf.exp(self.lambda_2)\n",
        "      if numpy:\n",
        "          return l1.numpy()[0], l2.numpy()[0]\n",
        "      return l1, l2\n",
        "\n",
        "    def fit(self, X_u, u):\n",
        "      self.X_u =  tf.convert_to_tensor(X_u, dtype=self.dtype)\n",
        "      super().fit(X_u, u)\n",
        "\n",
        "    def predict(self, X_star):\n",
        "      u_star = self.model(X_star)\n",
        "      f_star = self.f_model(X_star)\n",
        "      return u_star.numpy(), f_star.numpy()\n",
        "\n",
        "# %% TRAINING THE MODEL\n",
        "\n",
        "\n",
        "# Getting the data\n",
        "path = os.path.join(\"/content/drive/MyDrive/PINNs-TF2.0/1d-burgers/data\", \"burgers_shock.mat\")\n",
        "x, t, X, T, Exact_u, X_star, u_star, \\\n",
        "        X_u_train, u_train, ub, lb = prep_data(path, hp[\"N_u\"], noise=0.0)\n",
        "lambdas_star = (1.0, 0.01/np.pi)\n",
        "\n",
        "# Creating the model\n",
        "logger = Logger(hp)\n",
        "pinn = BurgersInformedNN(hp, logger, ub, lb)\n",
        "\n",
        "# Defining the error function for the logger and training\n",
        "def error():\n",
        "  l1, l2 = pinn.get_params(numpy=True)\n",
        "  l1_star, l2_star = lambdas_star\n",
        "  error_lambda_1 = np.abs(l1 - l1_star) / l1_star\n",
        "  error_lambda_2 = np.abs(l2 - l2_star) / l2_star\n",
        "  return (error_lambda_1 + error_lambda_2) / 2\n",
        "\n",
        "logger.set_error_fn(error)\n",
        "pinn.fit(X_u_train, u_train)\n",
        "\n",
        "# Getting the model predictions, from the same (x,t) that the predictions were previously gotten from\n",
        "u_pred, f_pred = pinn.predict(X_star)\n",
        "lambda_1_pred, lambda_2_pred = pinn.get_params(numpy=True)\n",
        "\n",
        "# Noise case\n",
        "x, t, X, T, Exact_u, X_star, u_star, \\\n",
        "        X_u_train, u_train, ub, lb = prep_data(path, hp[\"N_u\"], noise=0.01)\n",
        "pinn = BurgersInformedNN(hp, logger, ub, lb)\n",
        "pinn.fit(X_u_train, u_train)\n",
        "lambda_1_pred_noise, lambda_2_pred_noise = pinn.get_params(numpy=True)\n",
        "\n",
        "print(\"l1: \", lambda_1_pred)\n",
        "print(\"l2: \", lambda_2_pred)\n",
        "print(\"l1_noise: \", lambda_1_pred_noise)\n",
        "print(\"l2_noise: \", lambda_2_pred_noise)\n",
        "\n",
        "\n",
        "#%% PLOTTING\n",
        "plot_ide_cont_results(X_star, u_pred, X_u_train, u_train,\n",
        "        Exact_u, X, T, x, t, lambda_1_pred, lambda_1_pred_noise, lambda_2_pred, lambda_2_pred_noise)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyperparameters:\n",
            "{\n",
            "  \"N_u\": 2000,\n",
            "  \"layers\": [\n",
            "    2,\n",
            "    20,\n",
            "    20,\n",
            "    20,\n",
            "    20,\n",
            "    20,\n",
            "    20,\n",
            "    20,\n",
            "    20,\n",
            "    1\n",
            "  ],\n",
            "  \"tf_epochs\": 200,\n",
            "  \"tf_lr\": 0.01,\n",
            "  \"tf_b1\": 0.9,\n",
            "  \"tf_eps\": null,\n",
            "  \"nt_epochs\": 2000,\n",
            "  \"nt_lr\": 0.8,\n",
            "  \"nt_ncorr\": 50,\n",
            "  \"log_frequency\": 10\n",
            "}\n",
            "\n",
            "TensorFlow version: 2.4.1\n",
            "Eager execution: True\n",
            "GPU-accerelated: True\n",
            "\n",
            "Training started\n",
            "================\n",
            "-- Starting Adam optimization --\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "tf_epoch =      0  elapsed = 00:00 (+00.1)  loss = 3.0386e-01  \n",
            "tf_epoch =     10  elapsed = 00:00 (+00.7)  loss = 2.0169e-01  \n",
            "tf_epoch =     20  elapsed = 00:01 (+00.6)  loss = 7.4190e-02  \n",
            "tf_epoch =     30  elapsed = 00:02 (+00.6)  loss = 6.1795e-02  \n",
            "tf_epoch =     40  elapsed = 00:02 (+00.6)  loss = 4.3233e-02  \n",
            "tf_epoch =     50  elapsed = 00:03 (+00.6)  loss = 3.5507e-02  \n",
            "tf_epoch =     60  elapsed = 00:04 (+00.6)  loss = 3.1835e-02  \n",
            "tf_epoch =     70  elapsed = 00:04 (+00.6)  loss = 2.9835e-02  \n",
            "tf_epoch =     80  elapsed = 00:05 (+00.6)  loss = 2.8173e-02  \n",
            "tf_epoch =     90  elapsed = 00:06 (+00.6)  loss = 2.6831e-02  \n",
            "tf_epoch =    100  elapsed = 00:06 (+00.6)  loss = 2.5587e-02  \n",
            "tf_epoch =    110  elapsed = 00:07 (+00.6)  loss = 2.4365e-02  \n",
            "tf_epoch =    120  elapsed = 00:08 (+00.6)  loss = 2.3234e-02  \n",
            "tf_epoch =    130  elapsed = 00:08 (+00.6)  loss = 2.4136e-02  \n",
            "tf_epoch =    140  elapsed = 00:09 (+00.6)  loss = 2.1274e-02  \n",
            "tf_epoch =    150  elapsed = 00:10 (+00.6)  loss = 1.9807e-02  \n",
            "tf_epoch =    160  elapsed = 00:10 (+00.6)  loss = 1.8113e-02  \n",
            "tf_epoch =    170  elapsed = 00:11 (+00.6)  loss = 3.0718e-02  \n",
            "tf_epoch =    180  elapsed = 00:12 (+00.6)  loss = 1.8653e-02  \n",
            "tf_epoch =    190  elapsed = 00:12 (+00.6)  loss = 1.7819e-02  \n",
            "-- Starting LBFGS optimization --\n",
            "nt_epoch =     10  elapsed = 00:14 (+01.5)  loss = 1.5008e-02  \n",
            "nt_epoch =     20  elapsed = 00:15 (+00.8)  loss = 1.2807e-02  \n",
            "nt_epoch =     30  elapsed = 00:16 (+00.8)  loss = 1.0343e-02  \n",
            "nt_epoch =     40  elapsed = 00:16 (+00.8)  loss = 9.3445e-03  \n",
            "nt_epoch =     50  elapsed = 00:17 (+00.9)  loss = 8.4409e-03  \n",
            "nt_epoch =     60  elapsed = 00:18 (+00.9)  loss = 7.7074e-03  \n",
            "nt_epoch =     70  elapsed = 00:19 (+00.9)  loss = 6.8656e-03  \n",
            "nt_epoch =     80  elapsed = 00:20 (+01.0)  loss = 6.2543e-03  \n",
            "nt_epoch =     90  elapsed = 00:21 (+01.0)  loss = 5.8499e-03  \n",
            "nt_epoch =    100  elapsed = 00:22 (+00.9)  loss = 5.3569e-03  \n",
            "nt_epoch =    110  elapsed = 00:23 (+00.9)  loss = 4.8361e-03  \n",
            "nt_epoch =    120  elapsed = 00:24 (+00.9)  loss = 4.1997e-03  \n",
            "nt_epoch =    130  elapsed = 00:25 (+00.9)  loss = 4.0395e-03  \n",
            "nt_epoch =    140  elapsed = 00:26 (+00.9)  loss = 3.6438e-03  \n",
            "nt_epoch =    150  elapsed = 00:27 (+01.0)  loss = 3.3143e-03  \n",
            "nt_epoch =    160  elapsed = 00:28 (+01.0)  loss = 3.0037e-03  \n",
            "nt_epoch =    170  elapsed = 00:29 (+01.0)  loss = 2.6197e-03  \n",
            "nt_epoch =    180  elapsed = 00:30 (+01.0)  loss = 2.3839e-03  \n",
            "nt_epoch =    190  elapsed = 00:31 (+01.0)  loss = 2.2019e-03  \n",
            "nt_epoch =    200  elapsed = 00:32 (+00.9)  loss = 1.9959e-03  \n",
            "nt_epoch =    210  elapsed = 00:33 (+00.9)  loss = 1.7645e-03  \n",
            "nt_epoch =    220  elapsed = 00:34 (+01.0)  loss = 1.6383e-03  \n",
            "nt_epoch =    230  elapsed = 00:35 (+01.0)  loss = 1.4962e-03  \n",
            "nt_epoch =    240  elapsed = 00:36 (+00.9)  loss = 1.4243e-03  \n",
            "nt_epoch =    250  elapsed = 00:37 (+01.0)  loss = 1.3086e-03  \n",
            "nt_epoch =    260  elapsed = 00:38 (+00.9)  loss = 1.1838e-03  \n",
            "nt_epoch =    270  elapsed = 00:39 (+01.0)  loss = 1.0823e-03  \n",
            "nt_epoch =    280  elapsed = 00:40 (+01.0)  loss = 1.0082e-03  \n",
            "nt_epoch =    290  elapsed = 00:41 (+00.9)  loss = 9.6167e-04  \n",
            "nt_epoch =    300  elapsed = 00:42 (+00.9)  loss = 9.0599e-04  \n",
            "nt_epoch =    310  elapsed = 00:43 (+01.0)  loss = 8.5786e-04  \n",
            "nt_epoch =    320  elapsed = 00:44 (+00.9)  loss = 8.0826e-04  \n",
            "nt_epoch =    330  elapsed = 00:45 (+01.0)  loss = 7.6359e-04  \n",
            "nt_epoch =    340  elapsed = 00:46 (+01.0)  loss = 7.1347e-04  \n",
            "nt_epoch =    350  elapsed = 00:47 (+00.9)  loss = 6.5255e-04  \n",
            "nt_epoch =    360  elapsed = 00:48 (+01.0)  loss = 6.1394e-04  \n",
            "nt_epoch =    370  elapsed = 00:49 (+01.0)  loss = 5.7356e-04  \n",
            "nt_epoch =    380  elapsed = 00:50 (+00.9)  loss = 5.1373e-04  \n",
            "nt_epoch =    390  elapsed = 00:51 (+00.9)  loss = 4.9359e-04  \n",
            "nt_epoch =    400  elapsed = 00:52 (+01.0)  loss = 4.7971e-04  \n",
            "nt_epoch =    410  elapsed = 00:53 (+00.9)  loss = 4.4359e-04  \n",
            "nt_epoch =    420  elapsed = 00:54 (+01.0)  loss = 4.2319e-04  \n",
            "nt_epoch =    430  elapsed = 00:55 (+01.0)  loss = 3.9635e-04  \n",
            "nt_epoch =    440  elapsed = 00:56 (+01.0)  loss = 3.8261e-04  \n",
            "nt_epoch =    450  elapsed = 00:57 (+01.0)  loss = 3.6081e-04  \n",
            "nt_epoch =    460  elapsed = 00:58 (+01.0)  loss = 3.3905e-04  \n",
            "nt_epoch =    470  elapsed = 00:59 (+01.0)  loss = 3.2007e-04  \n",
            "nt_epoch =    480  elapsed = 01:00 (+01.0)  loss = 2.9558e-04  \n",
            "nt_epoch =    490  elapsed = 01:01 (+00.9)  loss = 2.7982e-04  \n",
            "nt_epoch =    500  elapsed = 01:02 (+00.9)  loss = 2.6829e-04  \n",
            "nt_epoch =    510  elapsed = 01:03 (+00.9)  loss = 2.5480e-04  \n",
            "nt_epoch =    520  elapsed = 01:04 (+01.0)  loss = 2.3844e-04  \n",
            "nt_epoch =    530  elapsed = 01:05 (+01.0)  loss = 2.3013e-04  \n",
            "nt_epoch =    540  elapsed = 01:06 (+01.0)  loss = 2.2253e-04  \n",
            "nt_epoch =    550  elapsed = 01:07 (+01.0)  loss = 2.1192e-04  \n",
            "nt_epoch =    560  elapsed = 01:08 (+00.9)  loss = 2.0314e-04  \n",
            "nt_epoch =    570  elapsed = 01:09 (+00.9)  loss = 1.9200e-04  \n",
            "nt_epoch =    580  elapsed = 01:10 (+00.9)  loss = 1.7755e-04  \n",
            "nt_epoch =    590  elapsed = 01:11 (+01.0)  loss = 1.6333e-04  \n",
            "nt_epoch =    600  elapsed = 01:12 (+00.9)  loss = 1.5158e-04  \n",
            "nt_epoch =    610  elapsed = 01:13 (+00.9)  loss = 1.4377e-04  \n",
            "nt_epoch =    620  elapsed = 01:14 (+00.9)  loss = 1.3721e-04  \n",
            "nt_epoch =    630  elapsed = 01:15 (+00.9)  loss = 1.2935e-04  \n",
            "nt_epoch =    640  elapsed = 01:16 (+00.9)  loss = 1.2379e-04  \n",
            "nt_epoch =    650  elapsed = 01:17 (+00.9)  loss = 1.1855e-04  \n",
            "nt_epoch =    660  elapsed = 01:18 (+01.0)  loss = 1.1255e-04  \n",
            "nt_epoch =    670  elapsed = 01:19 (+00.9)  loss = 1.0597e-04  \n",
            "nt_epoch =    680  elapsed = 01:20 (+00.9)  loss = 1.0022e-04  \n",
            "nt_epoch =    690  elapsed = 01:21 (+00.9)  loss = 9.5469e-05  \n",
            "nt_epoch =    700  elapsed = 01:22 (+00.9)  loss = 9.1117e-05  \n",
            "nt_epoch =    710  elapsed = 01:23 (+00.9)  loss = 8.6806e-05  \n",
            "nt_epoch =    720  elapsed = 01:24 (+01.0)  loss = 8.3765e-05  \n",
            "nt_epoch =    730  elapsed = 01:25 (+01.0)  loss = 8.1355e-05  \n",
            "nt_epoch =    740  elapsed = 01:26 (+00.9)  loss = 7.8982e-05  \n",
            "nt_epoch =    750  elapsed = 01:27 (+00.9)  loss = 7.5660e-05  \n",
            "nt_epoch =    760  elapsed = 01:28 (+00.9)  loss = 7.1291e-05  \n",
            "nt_epoch =    770  elapsed = 01:29 (+01.0)  loss = 6.8926e-05  \n",
            "nt_epoch =    780  elapsed = 01:30 (+00.9)  loss = 6.6887e-05  \n",
            "nt_epoch =    790  elapsed = 01:31 (+00.9)  loss = 6.5128e-05  \n",
            "nt_epoch =    800  elapsed = 01:32 (+01.0)  loss = 6.2533e-05  \n",
            "nt_epoch =    810  elapsed = 01:33 (+00.9)  loss = 6.0264e-05  \n",
            "nt_epoch =    820  elapsed = 01:34 (+01.0)  loss = 5.8400e-05  \n",
            "nt_epoch =    830  elapsed = 01:35 (+01.0)  loss = 5.7353e-05  \n",
            "nt_epoch =    840  elapsed = 01:36 (+01.0)  loss = 5.5668e-05  \n",
            "nt_epoch =    850  elapsed = 01:37 (+01.0)  loss = 5.3807e-05  \n",
            "nt_epoch =    860  elapsed = 01:38 (+00.9)  loss = 5.1659e-05  \n",
            "nt_epoch =    870  elapsed = 01:39 (+00.9)  loss = 4.9521e-05  \n",
            "nt_epoch =    880  elapsed = 01:40 (+00.9)  loss = 4.7475e-05  \n",
            "nt_epoch =    890  elapsed = 01:41 (+00.9)  loss = 4.5733e-05  \n",
            "nt_epoch =    900  elapsed = 01:42 (+00.9)  loss = 4.5069e-05  \n",
            "nt_epoch =    910  elapsed = 01:43 (+00.9)  loss = 4.3193e-05  \n",
            "nt_epoch =    920  elapsed = 01:44 (+01.0)  loss = 4.2352e-05  \n",
            "nt_epoch =    930  elapsed = 01:45 (+00.9)  loss = 4.1166e-05  \n",
            "nt_epoch =    940  elapsed = 01:46 (+00.9)  loss = 4.0250e-05  \n",
            "nt_epoch =    950  elapsed = 01:47 (+00.9)  loss = 3.9196e-05  \n",
            "nt_epoch =    960  elapsed = 01:48 (+01.0)  loss = 3.7978e-05  \n",
            "nt_epoch =    970  elapsed = 01:49 (+01.0)  loss = 3.6411e-05  \n",
            "nt_epoch =    980  elapsed = 01:50 (+01.0)  loss = 3.5003e-05  \n",
            "nt_epoch =    990  elapsed = 01:51 (+00.9)  loss = 3.3334e-05  \n",
            "nt_epoch =   1000  elapsed = 01:52 (+01.0)  loss = 3.3053e-05  \n",
            "nt_epoch =   1010  elapsed = 01:53 (+01.0)  loss = 3.1176e-05  \n",
            "nt_epoch =   1020  elapsed = 01:54 (+01.0)  loss = 3.0293e-05  \n",
            "nt_epoch =   1030  elapsed = 01:55 (+01.0)  loss = 2.9260e-05  \n",
            "nt_epoch =   1040  elapsed = 01:56 (+01.0)  loss = 2.8724e-05  \n",
            "nt_epoch =   1050  elapsed = 01:57 (+01.0)  loss = 2.8287e-05  \n",
            "nt_epoch =   1060  elapsed = 01:58 (+01.0)  loss = 2.7623e-05  \n",
            "nt_epoch =   1070  elapsed = 01:59 (+00.9)  loss = 2.6810e-05  \n",
            "nt_epoch =   1080  elapsed = 02:00 (+00.9)  loss = 2.6350e-05  \n",
            "nt_epoch =   1090  elapsed = 02:01 (+01.0)  loss = 2.5814e-05  \n",
            "nt_epoch =   1100  elapsed = 02:02 (+01.0)  loss = 2.5360e-05  \n",
            "nt_epoch =   1110  elapsed = 02:03 (+00.9)  loss = 2.4803e-05  \n",
            "nt_epoch =   1120  elapsed = 02:04 (+01.0)  loss = 2.4162e-05  \n",
            "nt_epoch =   1130  elapsed = 02:05 (+00.9)  loss = 2.3753e-05  \n",
            "nt_epoch =   1140  elapsed = 02:06 (+00.9)  loss = 2.3266e-05  \n",
            "nt_epoch =   1150  elapsed = 02:07 (+00.9)  loss = 2.2933e-05  \n",
            "nt_epoch =   1160  elapsed = 02:08 (+01.0)  loss = 2.2782e-05  \n",
            "nt_epoch =   1170  elapsed = 02:09 (+00.9)  loss = 2.2250e-05  \n",
            "nt_epoch =   1180  elapsed = 02:10 (+01.0)  loss = 2.1876e-05  \n",
            "nt_epoch =   1190  elapsed = 02:11 (+00.9)  loss = 2.1331e-05  \n",
            "nt_epoch =   1200  elapsed = 02:12 (+01.0)  loss = 2.1019e-05  \n",
            "nt_epoch =   1210  elapsed = 02:13 (+01.0)  loss = 2.0519e-05  \n",
            "nt_epoch =   1220  elapsed = 02:14 (+01.0)  loss = 2.0013e-05  \n",
            "nt_epoch =   1230  elapsed = 02:15 (+01.0)  loss = 1.9754e-05  \n",
            "nt_epoch =   1240  elapsed = 02:16 (+01.0)  loss = 1.9153e-05  \n",
            "nt_epoch =   1250  elapsed = 02:17 (+01.0)  loss = 1.8694e-05  \n",
            "nt_epoch =   1260  elapsed = 02:18 (+01.0)  loss = 1.8244e-05  \n",
            "nt_epoch =   1270  elapsed = 02:19 (+00.9)  loss = 1.7730e-05  \n",
            "nt_epoch =   1280  elapsed = 02:20 (+01.0)  loss = 1.7189e-05  \n",
            "nt_epoch =   1290  elapsed = 02:21 (+01.0)  loss = 1.6971e-05  \n",
            "nt_epoch =   1300  elapsed = 02:22 (+00.9)  loss = 1.6720e-05  \n",
            "nt_epoch =   1310  elapsed = 02:23 (+00.9)  loss = 1.6640e-05  \n",
            "nt_epoch =   1320  elapsed = 02:24 (+00.9)  loss = 1.6157e-05  \n",
            "nt_epoch =   1330  elapsed = 02:25 (+00.9)  loss = 1.5771e-05  \n",
            "nt_epoch =   1340  elapsed = 02:26 (+01.0)  loss = 1.5512e-05  \n",
            "nt_epoch =   1350  elapsed = 02:27 (+00.9)  loss = 1.5314e-05  \n",
            "nt_epoch =   1360  elapsed = 02:28 (+01.0)  loss = 1.4995e-05  \n",
            "nt_epoch =   1370  elapsed = 02:29 (+01.0)  loss = 1.4647e-05  \n",
            "nt_epoch =   1380  elapsed = 02:30 (+01.0)  loss = 1.4570e-05  \n",
            "nt_epoch =   1390  elapsed = 02:31 (+00.9)  loss = 1.3968e-05  \n",
            "nt_epoch =   1400  elapsed = 02:32 (+01.0)  loss = 1.3537e-05  \n",
            "nt_epoch =   1410  elapsed = 02:33 (+00.9)  loss = 1.3277e-05  \n",
            "nt_epoch =   1420  elapsed = 02:34 (+01.0)  loss = 1.2994e-05  \n",
            "nt_epoch =   1430  elapsed = 02:35 (+01.0)  loss = 1.2839e-05  \n",
            "nt_epoch =   1440  elapsed = 02:36 (+01.0)  loss = 1.2637e-05  \n",
            "nt_epoch =   1450  elapsed = 02:37 (+01.0)  loss = 1.2410e-05  \n",
            "nt_epoch =   1460  elapsed = 02:39 (+01.0)  loss = 1.2057e-05  \n",
            "nt_epoch =   1470  elapsed = 02:40 (+00.9)  loss = 1.1747e-05  \n",
            "nt_epoch =   1480  elapsed = 02:40 (+00.9)  loss = 1.1741e-05  \n",
            "nt_epoch =   1490  elapsed = 02:41 (+00.9)  loss = 1.1417e-05  \n",
            "nt_epoch =   1500  elapsed = 02:42 (+00.9)  loss = 1.1187e-05  \n",
            "nt_epoch =   1510  elapsed = 02:43 (+01.0)  loss = 1.0940e-05  \n",
            "nt_epoch =   1520  elapsed = 02:44 (+01.0)  loss = 1.0707e-05  \n",
            "nt_epoch =   1530  elapsed = 02:45 (+01.0)  loss = 1.0585e-05  \n",
            "nt_epoch =   1540  elapsed = 02:47 (+01.0)  loss = 1.0405e-05  \n",
            "nt_epoch =   1550  elapsed = 02:48 (+00.9)  loss = 1.0259e-05  \n",
            "nt_epoch =   1560  elapsed = 02:49 (+01.0)  loss = 1.0060e-05  \n",
            "nt_epoch =   1570  elapsed = 02:50 (+01.0)  loss = 9.9090e-06  \n",
            "nt_epoch =   1580  elapsed = 02:51 (+00.9)  loss = 9.7878e-06  \n",
            "nt_epoch =   1590  elapsed = 02:52 (+01.0)  loss = 9.6588e-06  \n",
            "nt_epoch =   1600  elapsed = 02:53 (+01.0)  loss = 9.5659e-06  \n",
            "nt_epoch =   1610  elapsed = 02:54 (+01.0)  loss = 9.4716e-06  \n",
            "nt_epoch =   1620  elapsed = 02:55 (+01.0)  loss = 9.3214e-06  \n",
            "nt_epoch =   1630  elapsed = 02:56 (+01.0)  loss = 9.2016e-06  \n",
            "nt_epoch =   1640  elapsed = 02:57 (+00.9)  loss = 9.0948e-06  \n",
            "nt_epoch =   1650  elapsed = 02:58 (+00.9)  loss = 9.0144e-06  \n",
            "nt_epoch =   1660  elapsed = 02:59 (+01.0)  loss = 8.9201e-06  \n",
            "nt_epoch =   1670  elapsed = 03:00 (+01.0)  loss = 8.8218e-06  \n",
            "nt_epoch =   1680  elapsed = 03:01 (+00.9)  loss = 8.7127e-06  \n",
            "nt_epoch =   1690  elapsed = 03:02 (+00.9)  loss = 8.6579e-06  \n",
            "nt_epoch =   1700  elapsed = 03:03 (+01.0)  loss = 8.6075e-06  \n",
            "nt_epoch =   1710  elapsed = 03:04 (+01.0)  loss = 8.5284e-06  \n",
            "nt_epoch =   1720  elapsed = 03:05 (+01.0)  loss = 8.4591e-06  \n",
            "nt_epoch =   1730  elapsed = 03:06 (+01.0)  loss = 8.3705e-06  \n",
            "nt_epoch =   1740  elapsed = 03:07 (+01.0)  loss = 8.2712e-06  \n",
            "nt_epoch =   1750  elapsed = 03:08 (+01.0)  loss = 8.2237e-06  \n",
            "nt_epoch =   1760  elapsed = 03:09 (+01.0)  loss = 8.1510e-06  \n",
            "nt_epoch =   1770  elapsed = 03:10 (+01.0)  loss = 8.1066e-06  \n",
            "nt_epoch =   1780  elapsed = 03:11 (+01.0)  loss = 8.0168e-06  \n",
            "nt_epoch =   1790  elapsed = 03:12 (+00.9)  loss = 7.9606e-06  \n",
            "nt_epoch =   1800  elapsed = 03:13 (+01.0)  loss = 7.8414e-06  \n",
            "nt_epoch =   1810  elapsed = 03:14 (+01.0)  loss = 7.7519e-06  \n",
            "nt_epoch =   1820  elapsed = 03:15 (+00.9)  loss = 7.6571e-06  \n",
            "nt_epoch =   1830  elapsed = 03:16 (+01.0)  loss = 7.5571e-06  \n",
            "nt_epoch =   1840  elapsed = 03:17 (+00.9)  loss = 7.4839e-06  \n",
            "nt_epoch =   1850  elapsed = 03:18 (+01.0)  loss = 7.3943e-06  \n",
            "nt_epoch =   1860  elapsed = 03:19 (+01.0)  loss = 7.3100e-06  \n",
            "nt_epoch =   1870  elapsed = 03:20 (+01.0)  loss = 7.2331e-06  \n",
            "nt_epoch =   1880  elapsed = 03:21 (+01.0)  loss = 7.1519e-06  \n",
            "nt_epoch =   1890  elapsed = 03:22 (+01.0)  loss = 7.0773e-06  \n",
            "nt_epoch =   1900  elapsed = 03:23 (+01.0)  loss = 7.0415e-06  \n",
            "nt_epoch =   1910  elapsed = 03:24 (+00.9)  loss = 6.9850e-06  \n",
            "nt_epoch =   1920  elapsed = 03:25 (+01.1)  loss = 6.9458e-06  \n",
            "nt_epoch =   1930  elapsed = 03:26 (+00.9)  loss = 6.9019e-06  \n",
            "nt_epoch =   1940  elapsed = 03:27 (+00.9)  loss = 6.8115e-06  \n",
            "nt_epoch =   1950  elapsed = 03:28 (+00.9)  loss = 6.7245e-06  \n",
            "nt_epoch =   1960  elapsed = 03:29 (+01.0)  loss = 6.6666e-06  \n",
            "nt_epoch =   1970  elapsed = 03:30 (+01.0)  loss = 6.5906e-06  \n",
            "nt_epoch =   1980  elapsed = 03:31 (+01.0)  loss = 6.5364e-06  \n",
            "nt_epoch =   1990  elapsed = 03:32 (+00.9)  loss = 6.4734e-06  \n",
            "==================\n",
            "Training finished (epoch 2200): duration = 03:33  error = 2.5763e-03  \n",
            "\n",
            "Training started\n",
            "================\n",
            "-- Starting Adam optimization --\n",
            "tf_epoch =      0  elapsed = 03:33 (+01.1)  loss = 4.2648e-01  \n",
            "tf_epoch =     10  elapsed = 03:34 (+00.6)  loss = 3.6782e-01  \n",
            "tf_epoch =     20  elapsed = 03:35 (+00.6)  loss = 1.6755e-01  \n",
            "tf_epoch =     30  elapsed = 03:35 (+00.6)  loss = 1.1281e-01  \n",
            "tf_epoch =     40  elapsed = 03:36 (+00.6)  loss = 6.8368e-02  \n",
            "tf_epoch =     50  elapsed = 03:37 (+00.6)  loss = 5.3439e-02  \n",
            "tf_epoch =     60  elapsed = 03:37 (+00.6)  loss = 4.4533e-02  \n",
            "tf_epoch =     70  elapsed = 03:38 (+00.6)  loss = 4.0548e-02  \n",
            "tf_epoch =     80  elapsed = 03:39 (+00.6)  loss = 3.7666e-02  \n",
            "tf_epoch =     90  elapsed = 03:39 (+00.6)  loss = 3.5806e-02  \n",
            "tf_epoch =    100  elapsed = 03:40 (+00.6)  loss = 3.4248e-02  \n",
            "tf_epoch =    110  elapsed = 03:41 (+00.6)  loss = 3.2913e-02  \n",
            "tf_epoch =    120  elapsed = 03:41 (+00.6)  loss = 3.1672e-02  \n",
            "tf_epoch =    130  elapsed = 03:42 (+00.6)  loss = 3.0471e-02  \n",
            "tf_epoch =    140  elapsed = 03:43 (+00.6)  loss = 2.9288e-02  \n",
            "tf_epoch =    150  elapsed = 03:43 (+00.6)  loss = 2.8112e-02  \n",
            "tf_epoch =    160  elapsed = 03:44 (+00.6)  loss = 2.6941e-02  \n",
            "tf_epoch =    170  elapsed = 03:45 (+00.6)  loss = 2.5793e-02  \n",
            "tf_epoch =    180  elapsed = 03:45 (+00.6)  loss = 2.4695e-02  \n",
            "tf_epoch =    190  elapsed = 03:46 (+00.6)  loss = 2.3674e-02  \n",
            "-- Starting LBFGS optimization --\n",
            "nt_epoch =     10  elapsed = 03:47 (+01.5)  loss = 2.0961e-02  \n",
            "nt_epoch =     20  elapsed = 03:48 (+00.8)  loss = 1.8172e-02  \n",
            "nt_epoch =     30  elapsed = 03:49 (+00.8)  loss = 1.6691e-02  \n",
            "nt_epoch =     40  elapsed = 03:50 (+00.9)  loss = 1.4578e-02  \n",
            "nt_epoch =     50  elapsed = 03:51 (+01.0)  loss = 1.2115e-02  \n",
            "nt_epoch =     60  elapsed = 03:52 (+00.9)  loss = 9.9825e-03  \n",
            "nt_epoch =     70  elapsed = 03:53 (+00.9)  loss = 8.7122e-03  \n",
            "nt_epoch =     80  elapsed = 03:54 (+01.0)  loss = 7.7987e-03  \n",
            "nt_epoch =     90  elapsed = 03:55 (+00.9)  loss = 6.7378e-03  \n",
            "nt_epoch =    100  elapsed = 03:56 (+00.9)  loss = 5.9469e-03  \n",
            "nt_epoch =    110  elapsed = 03:57 (+00.9)  loss = 5.2379e-03  \n",
            "nt_epoch =    120  elapsed = 03:58 (+00.9)  loss = 4.5949e-03  \n",
            "nt_epoch =    130  elapsed = 03:59 (+00.9)  loss = 4.1274e-03  \n",
            "nt_epoch =    140  elapsed = 04:00 (+00.9)  loss = 3.6709e-03  \n",
            "nt_epoch =    150  elapsed = 04:01 (+00.9)  loss = 3.3528e-03  \n",
            "nt_epoch =    160  elapsed = 04:02 (+00.9)  loss = 3.1651e-03  \n",
            "nt_epoch =    170  elapsed = 04:03 (+00.9)  loss = 2.8133e-03  \n",
            "nt_epoch =    180  elapsed = 04:04 (+00.9)  loss = 2.5603e-03  \n",
            "nt_epoch =    190  elapsed = 04:05 (+01.0)  loss = 2.2580e-03  \n",
            "nt_epoch =    200  elapsed = 04:06 (+00.9)  loss = 2.0622e-03  \n",
            "nt_epoch =    210  elapsed = 04:07 (+00.9)  loss = 1.9331e-03  \n",
            "nt_epoch =    220  elapsed = 04:08 (+00.9)  loss = 1.8076e-03  \n",
            "nt_epoch =    230  elapsed = 04:09 (+01.0)  loss = 1.7031e-03  \n",
            "nt_epoch =    240  elapsed = 04:10 (+01.0)  loss = 1.6209e-03  \n",
            "nt_epoch =    250  elapsed = 04:11 (+01.0)  loss = 1.4926e-03  \n",
            "nt_epoch =    260  elapsed = 04:12 (+01.0)  loss = 1.4001e-03  \n",
            "nt_epoch =    270  elapsed = 04:13 (+01.0)  loss = 1.2615e-03  \n",
            "nt_epoch =    280  elapsed = 04:14 (+00.9)  loss = 1.1600e-03  \n",
            "nt_epoch =    290  elapsed = 04:15 (+00.9)  loss = 1.0802e-03  \n",
            "nt_epoch =    300  elapsed = 04:16 (+01.0)  loss = 9.9312e-04  \n",
            "nt_epoch =    310  elapsed = 04:17 (+00.9)  loss = 9.5236e-04  \n",
            "nt_epoch =    320  elapsed = 04:18 (+00.9)  loss = 1.0014e-03  \n",
            "nt_epoch =    330  elapsed = 04:19 (+00.9)  loss = 8.4156e-04  \n",
            "nt_epoch =    340  elapsed = 04:20 (+01.0)  loss = 7.9940e-04  \n",
            "nt_epoch =    350  elapsed = 04:21 (+01.0)  loss = 7.6170e-04  \n",
            "nt_epoch =    360  elapsed = 04:22 (+00.9)  loss = 7.1864e-04  \n",
            "nt_epoch =    370  elapsed = 04:23 (+00.9)  loss = 6.8112e-04  \n",
            "nt_epoch =    380  elapsed = 04:24 (+00.9)  loss = 6.4777e-04  \n",
            "nt_epoch =    390  elapsed = 04:25 (+01.0)  loss = 6.2729e-04  \n",
            "nt_epoch =    400  elapsed = 04:26 (+01.0)  loss = 6.1058e-04  \n",
            "nt_epoch =    410  elapsed = 04:27 (+01.0)  loss = 5.9154e-04  \n",
            "nt_epoch =    420  elapsed = 04:28 (+01.0)  loss = 5.6786e-04  \n",
            "nt_epoch =    430  elapsed = 04:29 (+00.9)  loss = 5.3300e-04  \n",
            "nt_epoch =    440  elapsed = 04:30 (+00.9)  loss = 4.9854e-04  \n",
            "nt_epoch =    450  elapsed = 04:31 (+01.0)  loss = 4.8223e-04  \n",
            "nt_epoch =    460  elapsed = 04:32 (+01.0)  loss = 4.5881e-04  \n",
            "nt_epoch =    470  elapsed = 04:33 (+00.9)  loss = 4.3354e-04  \n",
            "nt_epoch =    480  elapsed = 04:34 (+01.0)  loss = 4.1370e-04  \n",
            "nt_epoch =    490  elapsed = 04:35 (+01.0)  loss = 3.9235e-04  \n",
            "nt_epoch =    500  elapsed = 04:36 (+01.0)  loss = 3.7222e-04  \n",
            "nt_epoch =    510  elapsed = 04:37 (+01.0)  loss = 3.5811e-04  \n",
            "nt_epoch =    520  elapsed = 04:38 (+00.9)  loss = 3.4319e-04  \n",
            "nt_epoch =    530  elapsed = 04:39 (+00.9)  loss = 3.2891e-04  \n",
            "nt_epoch =    540  elapsed = 04:40 (+01.0)  loss = 3.1499e-04  \n",
            "nt_epoch =    550  elapsed = 04:41 (+01.0)  loss = 3.0068e-04  \n",
            "nt_epoch =    560  elapsed = 04:42 (+01.0)  loss = 2.8727e-04  \n",
            "nt_epoch =    570  elapsed = 04:43 (+00.9)  loss = 2.7319e-04  \n",
            "nt_epoch =    580  elapsed = 04:44 (+00.9)  loss = 2.6344e-04  \n",
            "nt_epoch =    590  elapsed = 04:45 (+00.9)  loss = 2.5679e-04  \n",
            "nt_epoch =    600  elapsed = 04:46 (+01.0)  loss = 2.4301e-04  \n",
            "nt_epoch =    610  elapsed = 04:47 (+01.0)  loss = 2.3620e-04  \n",
            "nt_epoch =    620  elapsed = 04:48 (+00.9)  loss = 2.2710e-04  \n",
            "nt_epoch =    630  elapsed = 04:49 (+00.9)  loss = 2.1915e-04  \n",
            "nt_epoch =    640  elapsed = 04:50 (+01.0)  loss = 2.1343e-04  \n",
            "nt_epoch =    650  elapsed = 04:51 (+01.0)  loss = 2.0877e-04  \n",
            "nt_epoch =    660  elapsed = 04:52 (+01.0)  loss = 2.0594e-04  \n",
            "nt_epoch =    670  elapsed = 04:53 (+01.0)  loss = 2.0261e-04  \n",
            "nt_epoch =    680  elapsed = 04:54 (+00.9)  loss = 2.0100e-04  \n",
            "nt_epoch =    690  elapsed = 04:55 (+00.9)  loss = 1.9366e-04  \n",
            "nt_epoch =    700  elapsed = 04:56 (+00.9)  loss = 1.8881e-04  \n",
            "nt_epoch =    710  elapsed = 04:57 (+00.9)  loss = 1.8516e-04  \n",
            "nt_epoch =    720  elapsed = 04:58 (+00.9)  loss = 1.8264e-04  \n",
            "nt_epoch =    730  elapsed = 04:59 (+00.9)  loss = 1.7744e-04  \n",
            "nt_epoch =    740  elapsed = 05:00 (+01.0)  loss = 1.7357e-04  \n",
            "nt_epoch =    750  elapsed = 05:01 (+00.9)  loss = 1.6911e-04  \n",
            "nt_epoch =    760  elapsed = 05:02 (+00.9)  loss = 1.6339e-04  \n",
            "nt_epoch =    770  elapsed = 05:03 (+00.9)  loss = 1.6012e-04  \n",
            "nt_epoch =    780  elapsed = 05:04 (+01.0)  loss = 1.5699e-04  \n",
            "nt_epoch =    790  elapsed = 05:05 (+00.9)  loss = 1.5386e-04  \n",
            "nt_epoch =    800  elapsed = 05:06 (+01.0)  loss = 1.5112e-04  \n",
            "nt_epoch =    810  elapsed = 05:07 (+00.9)  loss = 1.4890e-04  \n",
            "nt_epoch =    820  elapsed = 05:08 (+01.0)  loss = 1.4773e-04  \n",
            "nt_epoch =    830  elapsed = 05:09 (+00.9)  loss = 1.4538e-04  \n",
            "nt_epoch =    840  elapsed = 05:10 (+01.0)  loss = 1.4303e-04  \n",
            "nt_epoch =    850  elapsed = 05:11 (+00.9)  loss = 1.4082e-04  \n",
            "nt_epoch =    860  elapsed = 05:12 (+00.9)  loss = 1.3791e-04  \n",
            "nt_epoch =    870  elapsed = 05:13 (+00.9)  loss = 1.3626e-04  \n",
            "nt_epoch =    880  elapsed = 05:14 (+00.9)  loss = 1.3561e-04  \n",
            "nt_epoch =    890  elapsed = 05:15 (+00.9)  loss = 1.3354e-04  \n",
            "nt_epoch =    900  elapsed = 05:16 (+00.9)  loss = 1.3140e-04  \n",
            "nt_epoch =    910  elapsed = 05:17 (+00.9)  loss = 1.2934e-04  \n",
            "nt_epoch =    920  elapsed = 05:18 (+00.9)  loss = 1.2640e-04  \n",
            "nt_epoch =    930  elapsed = 05:19 (+01.0)  loss = 1.2450e-04  \n",
            "nt_epoch =    940  elapsed = 05:20 (+00.9)  loss = 1.2672e-04  \n",
            "nt_epoch =    950  elapsed = 05:21 (+00.9)  loss = 1.1903e-04  \n",
            "nt_epoch =    960  elapsed = 05:22 (+00.9)  loss = 1.1633e-04  \n",
            "nt_epoch =    970  elapsed = 05:23 (+00.9)  loss = 1.1405e-04  \n",
            "nt_epoch =    980  elapsed = 05:24 (+01.0)  loss = 1.1289e-04  \n",
            "nt_epoch =    990  elapsed = 05:25 (+00.9)  loss = 1.1026e-04  \n",
            "nt_epoch =   1000  elapsed = 05:26 (+01.0)  loss = 1.0663e-04  \n",
            "nt_epoch =   1010  elapsed = 05:27 (+00.9)  loss = 1.0524e-04  \n",
            "nt_epoch =   1020  elapsed = 05:28 (+00.9)  loss = 1.0355e-04  \n",
            "nt_epoch =   1030  elapsed = 05:29 (+00.9)  loss = 1.0157e-04  \n",
            "nt_epoch =   1040  elapsed = 05:30 (+01.0)  loss = 9.9593e-05  \n",
            "nt_epoch =   1050  elapsed = 05:31 (+01.0)  loss = 9.7331e-05  \n",
            "nt_epoch =   1060  elapsed = 05:32 (+00.9)  loss = 9.4026e-05  \n",
            "nt_epoch =   1070  elapsed = 05:33 (+01.0)  loss = 9.2212e-05  \n",
            "nt_epoch =   1080  elapsed = 05:34 (+01.0)  loss = 9.1064e-05  \n",
            "nt_epoch =   1090  elapsed = 05:35 (+01.0)  loss = 8.9717e-05  \n",
            "nt_epoch =   1100  elapsed = 05:36 (+00.9)  loss = 8.8719e-05  \n",
            "nt_epoch =   1110  elapsed = 05:37 (+01.0)  loss = 8.7871e-05  \n",
            "nt_epoch =   1120  elapsed = 05:38 (+01.0)  loss = 8.6966e-05  \n",
            "nt_epoch =   1130  elapsed = 05:39 (+01.0)  loss = 8.6180e-05  \n",
            "nt_epoch =   1140  elapsed = 05:40 (+01.0)  loss = 8.8857e-05  \n",
            "nt_epoch =   1150  elapsed = 05:41 (+01.0)  loss = 8.4599e-05  \n",
            "nt_epoch =   1160  elapsed = 05:42 (+01.0)  loss = 8.3906e-05  \n",
            "nt_epoch =   1170  elapsed = 05:43 (+01.0)  loss = 8.2729e-05  \n",
            "nt_epoch =   1180  elapsed = 05:44 (+00.9)  loss = 8.1892e-05  \n",
            "nt_epoch =   1190  elapsed = 05:45 (+01.0)  loss = 8.1041e-05  \n",
            "nt_epoch =   1200  elapsed = 05:46 (+01.0)  loss = 8.0277e-05  \n",
            "nt_epoch =   1210  elapsed = 05:47 (+01.0)  loss = 7.9514e-05  \n",
            "nt_epoch =   1220  elapsed = 05:48 (+00.9)  loss = 7.8285e-05  \n",
            "nt_epoch =   1230  elapsed = 05:49 (+00.9)  loss = 7.7515e-05  \n",
            "nt_epoch =   1240  elapsed = 05:50 (+01.0)  loss = 7.6920e-05  \n",
            "nt_epoch =   1250  elapsed = 05:51 (+00.9)  loss = 7.6178e-05  \n",
            "nt_epoch =   1260  elapsed = 05:52 (+01.0)  loss = 7.5421e-05  \n",
            "nt_epoch =   1270  elapsed = 05:53 (+01.0)  loss = 7.4654e-05  \n",
            "nt_epoch =   1280  elapsed = 05:54 (+01.0)  loss = 7.4093e-05  \n",
            "nt_epoch =   1290  elapsed = 05:55 (+01.0)  loss = 7.3624e-05  \n",
            "nt_epoch =   1300  elapsed = 05:56 (+01.0)  loss = 7.2998e-05  \n",
            "nt_epoch =   1310  elapsed = 05:57 (+01.0)  loss = 7.2451e-05  \n",
            "nt_epoch =   1320  elapsed = 05:58 (+01.0)  loss = 7.1644e-05  \n",
            "nt_epoch =   1330  elapsed = 05:59 (+01.0)  loss = 7.1064e-05  \n",
            "nt_epoch =   1340  elapsed = 06:00 (+00.9)  loss = 7.1034e-05  \n",
            "nt_epoch =   1350  elapsed = 06:01 (+00.9)  loss = 7.0340e-05  \n",
            "nt_epoch =   1360  elapsed = 06:02 (+00.9)  loss = 6.9916e-05  \n",
            "nt_epoch =   1370  elapsed = 06:03 (+00.9)  loss = 6.8799e-05  \n",
            "nt_epoch =   1380  elapsed = 06:04 (+01.0)  loss = 6.8035e-05  \n",
            "nt_epoch =   1390  elapsed = 06:05 (+00.9)  loss = 6.7394e-05  \n",
            "nt_epoch =   1400  elapsed = 06:06 (+01.0)  loss = 6.6609e-05  \n",
            "nt_epoch =   1410  elapsed = 06:07 (+01.0)  loss = 6.6112e-05  \n",
            "nt_epoch =   1420  elapsed = 06:08 (+00.9)  loss = 6.5477e-05  \n",
            "nt_epoch =   1430  elapsed = 06:09 (+00.9)  loss = 6.4772e-05  \n",
            "nt_epoch =   1440  elapsed = 06:10 (+00.9)  loss = 6.3816e-05  \n",
            "nt_epoch =   1450  elapsed = 06:11 (+00.9)  loss = 6.3067e-05  \n",
            "nt_epoch =   1460  elapsed = 06:12 (+01.0)  loss = 6.1798e-05  \n",
            "nt_epoch =   1470  elapsed = 06:13 (+01.0)  loss = 6.1188e-05  \n",
            "nt_epoch =   1480  elapsed = 06:14 (+01.0)  loss = 6.0271e-05  \n",
            "nt_epoch =   1490  elapsed = 06:15 (+01.0)  loss = 5.9116e-05  \n",
            "nt_epoch =   1500  elapsed = 06:16 (+01.0)  loss = 5.9475e-05  \n",
            "nt_epoch =   1510  elapsed = 06:17 (+01.0)  loss = 5.7447e-05  \n",
            "nt_epoch =   1520  elapsed = 06:18 (+01.0)  loss = 5.6890e-05  \n",
            "nt_epoch =   1530  elapsed = 06:19 (+01.0)  loss = 5.5692e-05  \n",
            "nt_epoch =   1540  elapsed = 06:20 (+00.9)  loss = 5.4423e-05  \n",
            "nt_epoch =   1550  elapsed = 06:21 (+01.0)  loss = 5.3800e-05  \n",
            "nt_epoch =   1560  elapsed = 06:22 (+01.0)  loss = 5.3276e-05  \n",
            "nt_epoch =   1570  elapsed = 06:23 (+01.0)  loss = 5.2578e-05  \n",
            "nt_epoch =   1580  elapsed = 06:24 (+00.9)  loss = 5.1769e-05  \n",
            "nt_epoch =   1590  elapsed = 06:25 (+01.0)  loss = 5.0209e-05  \n",
            "nt_epoch =   1600  elapsed = 06:26 (+01.0)  loss = 4.9529e-05  \n",
            "nt_epoch =   1610  elapsed = 06:27 (+01.0)  loss = 4.9161e-05  \n",
            "nt_epoch =   1620  elapsed = 06:28 (+01.0)  loss = 4.8416e-05  \n",
            "nt_epoch =   1630  elapsed = 06:29 (+00.9)  loss = 4.7708e-05  \n",
            "nt_epoch =   1640  elapsed = 06:30 (+01.0)  loss = 4.7093e-05  \n",
            "nt_epoch =   1650  elapsed = 06:31 (+00.9)  loss = 4.6645e-05  \n",
            "nt_epoch =   1660  elapsed = 06:32 (+01.0)  loss = 4.5953e-05  \n",
            "nt_epoch =   1670  elapsed = 06:33 (+01.0)  loss = 4.5585e-05  \n",
            "nt_epoch =   1680  elapsed = 06:34 (+00.9)  loss = 4.5123e-05  \n",
            "nt_epoch =   1690  elapsed = 06:36 (+01.0)  loss = 4.4585e-05  \n",
            "nt_epoch =   1700  elapsed = 06:37 (+01.0)  loss = 4.4336e-05  \n",
            "nt_epoch =   1710  elapsed = 06:38 (+00.9)  loss = 4.4031e-05  \n",
            "nt_epoch =   1720  elapsed = 06:38 (+00.9)  loss = 4.3704e-05  \n",
            "nt_epoch =   1730  elapsed = 06:39 (+00.9)  loss = 4.3409e-05  \n",
            "nt_epoch =   1740  elapsed = 06:40 (+01.0)  loss = 4.2992e-05  \n",
            "nt_epoch =   1750  elapsed = 06:41 (+00.9)  loss = 4.2575e-05  \n",
            "nt_epoch =   1760  elapsed = 06:42 (+01.0)  loss = 4.2256e-05  \n",
            "nt_epoch =   1770  elapsed = 06:44 (+01.0)  loss = 4.1705e-05  \n",
            "nt_epoch =   1780  elapsed = 06:45 (+01.0)  loss = 4.1285e-05  \n",
            "nt_epoch =   1790  elapsed = 06:45 (+00.9)  loss = 4.0943e-05  \n",
            "nt_epoch =   1800  elapsed = 06:46 (+00.9)  loss = 4.0776e-05  \n",
            "nt_epoch =   1810  elapsed = 06:47 (+00.9)  loss = 4.0189e-05  \n",
            "nt_epoch =   1820  elapsed = 06:48 (+01.0)  loss = 3.9754e-05  \n",
            "nt_epoch =   1830  elapsed = 06:49 (+01.0)  loss = 3.9337e-05  \n",
            "nt_epoch =   1840  elapsed = 06:50 (+00.9)  loss = 3.9134e-05  \n",
            "nt_epoch =   1850  elapsed = 06:51 (+00.9)  loss = 3.8925e-05  \n",
            "nt_epoch =   1860  elapsed = 06:52 (+00.9)  loss = 3.8598e-05  \n",
            "nt_epoch =   1870  elapsed = 06:53 (+01.0)  loss = 3.7964e-05  \n",
            "nt_epoch =   1880  elapsed = 06:55 (+01.0)  loss = 3.7445e-05  \n",
            "nt_epoch =   1890  elapsed = 06:56 (+01.0)  loss = 3.6676e-05  \n",
            "nt_epoch =   1900  elapsed = 06:57 (+01.0)  loss = 3.6205e-05  \n",
            "nt_epoch =   1910  elapsed = 06:58 (+00.9)  loss = 3.5798e-05  \n",
            "nt_epoch =   1920  elapsed = 06:59 (+01.0)  loss = 3.5385e-05  \n",
            "nt_epoch =   1930  elapsed = 07:00 (+00.9)  loss = 3.4716e-05  \n",
            "nt_epoch =   1940  elapsed = 07:01 (+00.9)  loss = 3.4264e-05  \n",
            "nt_epoch =   1950  elapsed = 07:02 (+00.9)  loss = 3.3773e-05  \n",
            "nt_epoch =   1960  elapsed = 07:03 (+00.9)  loss = 3.3413e-05  \n",
            "nt_epoch =   1970  elapsed = 07:03 (+00.9)  loss = 3.2890e-05  \n",
            "nt_epoch =   1980  elapsed = 07:04 (+00.9)  loss = 3.2499e-05  \n",
            "nt_epoch =   1990  elapsed = 07:05 (+01.0)  loss = 3.2115e-05  \n",
            "==================\n",
            "Training finished (epoch 2200): duration = 07:06  error = 8.3595e-03  \n",
            "l1:  0.9998111184497595\n",
            "l2:  0.0031988987602839425\n",
            "l1_noise:  0.9970345960036966\n",
            "l2_noise:  0.0032268781415552756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 388.543x336.186 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-b63797e1ea53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;31m#%% PLOTTING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m plot_ide_cont_results(X_star, u_pred, X_u_train, u_train,\n\u001b[0;32m--> 150\u001b[0;31m         Exact_u, X, T, x, t, lambda_1_pred, lambda_1_pred_noise, lambda_2_pred, lambda_2_pred_noise)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-2c0fcb929bc3>\u001b[0m in \u001b[0;36mplot_ide_cont_results\u001b[0;34m(X_star, u_pred, X_u_train, u_train, Exact_u, X, T, x, t, lambda_1_value, lambda_1_value_noisy, lambda_2_value, lambda_2_value_noisy)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m     \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./content/Burgers_identification'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-b6b060b4cce6>\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(filename, crop)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcrop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m#        plt.savefig('{}.pgf'.format(filename), bbox_inches='tight', pad_inches=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}.pdf'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;31m# plt.savefig('{}.eps'.format(filename), bbox_inches='tight', pad_inches=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}.png'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2127\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_pdf.py\u001b[0m in \u001b[0;36mprint_pdf\u001b[0;34m(self, filename, dpi, bbox_inches_restore, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   2539\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2541\u001b[0;31m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdfFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2542\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2543\u001b[0m             \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewPage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, metadata)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_file_like\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_opened\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './content/Burgers_identification.pdf'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 388.543x240.133 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLL85HUR_otN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}